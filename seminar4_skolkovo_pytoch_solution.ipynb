{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wK9adcjNlteK"
   },
   "source": [
    "## Reccurent Neural Network and Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J95PhAaGlteQ"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sayankotor/nlp_skolkovo/blob/master/seminar4_skolkovo_pytoch_solution.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0THE5d_3lteS"
   },
   "source": [
    "### 0 step. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding of LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1920px-The_LSTM_cell.png' width=480px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for the LSTM looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{ll} \\\\\n",
    "            i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "            f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "            g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "            o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\\n",
    "            \\textbf{c_t = f_t * c_{(t-1)} + i_t * g_t} \\\\\n",
    "            h_t = o_t * \\tanh(c_t) \\\\\n",
    "        \\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In bold is the equation that describes the change in the state of the cell, this is the **LSTM state update rule**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why LSTM, not RNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYUFFDQ2lteU"
   },
   "source": [
    "<img src='https://memeworld.funnyjunk.com/pictures/The+tragedy+of+a+three+second+memory_b414ea_4853499.jpg' width=480px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbQk5d-alteV"
   },
   "source": [
    "We need a \"long\" memory.\n",
    "\n",
    " __He__ doesn't have very much confidents in __himself__.\n",
    " \n",
    " __She__ doesn't have very much confidents in __herself__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dv35yNwRxr6R"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1eqfPpRMsK6lJemwZtqVJW8hKFqT7bckv' width=680px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kb_5L_3Mlted"
   },
   "source": [
    "* The hidden state in RNN (**RNN update rule**):\n",
    "    $h_t = tanh(h_{t-1}W_h + x_t W_x)$\n",
    "\n",
    "* Gradient (state derivative by weights):\n",
    "\n",
    "$$\\frac{\\partial{h_t}}{\\partial W_h} = \\sum_{k =0 ..t}\\frac{\\partial{h_t}}{\\partial {h_k}}\\cdot\\frac{\\partial{h_k}}{\\partial {W_k}}$$\n",
    "    \n",
    "$$\\frac{\\partial{h_t}}{\\partial {h_k}}=\\prod_{i=k+1..t}\\frac{\\partial{h_i}}{\\partial {h_{i-1}}} \\approx W_h^{t - k}$$\n",
    "\n",
    " if norm($W_h$) > 1 -> gradient explodes \n",
    " \n",
    " if norm($W_h$) < 1 -> gradient vanishes (\"three second memory\")\n",
    "\n",
    "* The core of the LSTM is the following equation:\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "            c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "\\end{array}\n",
    "\n",
    "$$\\frac{\\partial{c_t}}{\\partial {c_k}} \\approx \\prod_{i=k+1..t} f_i$$\n",
    "\n",
    "Look's more simple than RNN, isn't it?\n",
    "\n",
    "* LSTM stores \"memory state\". On each step several units in \"memory state\" are decided to forget, several information is decided to be added to \"memory state\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To warm up, lets buld and try on simple task our own LSTM cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "\n",
    "from typing import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "class Dim(IntEnum):\n",
    "    batch = 0\n",
    "    seq = 1\n",
    "    feature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveLSTM(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        # input gate\n",
    "        self.W_ii = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hi = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = Parameter(torch.Tensor(hidden_sz))\n",
    "        # forget gate\n",
    "        self.W_if = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hf = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = Parameter(torch.Tensor(hidden_sz))\n",
    "        # ???\n",
    "        self.W_ig = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hg = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_g = Parameter(torch.Tensor(hidden_sz))\n",
    "        # output gate\n",
    "        self.W_io = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_ho = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, \n",
    "                init_states: Optional[Tuple[torch.Tensor, torch.Tensor]]=None\n",
    "               ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "        for t in range(seq_sz): # iterate over the time steps\n",
    "            x_t = x[:, t, :]\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ii + h_t @ self.W_hi + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.W_if + h_t @ self.W_hf + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.W_ig + h_t @ self.W_hg + self.b_g)\n",
    "            o_t = torch.sigmoid(x_t @ self.W_io + h_t @ self.W_ho + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            hidden_seq.append(h_t.unsqueeze(Dim.batch))\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=Dim.batch)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(Dim.batch, Dim.seq).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seq_len, feat_sz, hidden_sz = 5, 10, 32, 16\n",
    "arr = torch.randn(bs, seq_len, feat_sz)\n",
    "lstm = NaiveLSTM(feat_sz, hidden_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs, (hn, cn) = lstm(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5VPvhTRltef"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
    "\n",
    "There is title's and abstracts of ML-articles from 1992 to 2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "s52W9paClteg",
    "outputId": "9ba2784e-b3a2-4e47-d6b7-f88d18188f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-13 11:15:46--  https://docs.google.com/uc?export=download&id=1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9\n",
      "Connecting to 165.225.66.34:10015... ^C\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9' -O arxivData.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFJkPlPol9Eu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxivData.json\t\t\t\t seminar4_skolkovo_pytorch.ipynb\r\n",
      "seminar4_skolkovo.ipynb\t\t\t seminar4_skolkovo_solution.ipynb\r\n",
      "seminar4_skolkovo_pytoch_solution.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alJt9QVbltel"
   },
   "outputs": [],
   "source": [
    "#!tar -xvzf arxivData.json.tar.gz\n",
    "data = pd.read_json(\"./arxivData.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "bq9EpY26ltep",
    "outputId": "46b5da9b-6652-46fa-fdbc-478688c529f7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[{'name': 'Ahmed Osman'}, {'name': 'Wojciech S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1802.00209v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>2</td>\n",
       "      <td>We propose an architecture for VQA which utili...</td>\n",
       "      <td>[{'term': 'cs.AI', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Dual Recurrent Attention Units for Visual Ques...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[{'name': 'Ji Young Lee'}, {'name': 'Franck De...</td>\n",
       "      <td>12</td>\n",
       "      <td>1603.03827v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent approaches based on artificial neural n...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Sequential Short-Text Classification with Recu...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[{'name': 'Iulian Vlad Serban'}, {'name': 'Tim...</td>\n",
       "      <td>2</td>\n",
       "      <td>1606.00776v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>6</td>\n",
       "      <td>We introduce the multiresolution recurrent neu...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Multiresolution Recurrent Neural Networks: An ...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[{'name': 'Sebastian Ruder'}, {'name': 'Joachi...</td>\n",
       "      <td>23</td>\n",
       "      <td>1705.08142v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>5</td>\n",
       "      <td>Multi-task learning is motivated by the observ...</td>\n",
       "      <td>[{'term': 'stat.ML', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>Learning what to share between loosely related...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[{'name': 'Iulian V. Serban'}, {'name': 'Chinn...</td>\n",
       "      <td>7</td>\n",
       "      <td>1709.02349v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>9</td>\n",
       "      <td>We present MILABOT: a deep reinforcement learn...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              author  day            id  \\\n",
       "0  [{'name': 'Ahmed Osman'}, {'name': 'Wojciech S...    1  1802.00209v1   \n",
       "1  [{'name': 'Ji Young Lee'}, {'name': 'Franck De...   12  1603.03827v1   \n",
       "2  [{'name': 'Iulian Vlad Serban'}, {'name': 'Tim...    2  1606.00776v2   \n",
       "3  [{'name': 'Sebastian Ruder'}, {'name': 'Joachi...   23  1705.08142v2   \n",
       "4  [{'name': 'Iulian V. Serban'}, {'name': 'Chinn...    7  1709.02349v2   \n",
       "\n",
       "                                                link  month  \\\n",
       "0  [{'rel': 'alternate', 'href': 'http://arxiv.or...      2   \n",
       "1  [{'rel': 'alternate', 'href': 'http://arxiv.or...      3   \n",
       "2  [{'rel': 'alternate', 'href': 'http://arxiv.or...      6   \n",
       "3  [{'rel': 'alternate', 'href': 'http://arxiv.or...      5   \n",
       "4  [{'rel': 'alternate', 'href': 'http://arxiv.or...      9   \n",
       "\n",
       "                                             summary  \\\n",
       "0  We propose an architecture for VQA which utili...   \n",
       "1  Recent approaches based on artificial neural n...   \n",
       "2  We introduce the multiresolution recurrent neu...   \n",
       "3  Multi-task learning is motivated by the observ...   \n",
       "4  We present MILABOT: a deep reinforcement learn...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  [{'term': 'cs.AI', 'scheme': 'http://arxiv.org...   \n",
       "1  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
       "2  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
       "3  [{'term': 'stat.ML', 'scheme': 'http://arxiv.o...   \n",
       "4  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
       "\n",
       "                                               title  year  \n",
       "0  Dual Recurrent Attention Units for Visual Ques...  2018  \n",
       "1  Sequential Short-Text Classification with Recu...  2016  \n",
       "2  Multiresolution Recurrent Neural Networks: An ...  2016  \n",
       "3  Learning what to share between loosely related...  2017  \n",
       "4              A Deep Reinforcement Learning Chatbot  2017  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "vquMzWL5owbg",
    "outputId": "08a9fc37-eba6-4fd9-dbc3-c13aa6590456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset, performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmechanisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.'\n",
      " 'Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\\nand most existing ANN-based systems do not leverage the preceding short texts\\nwhen classifying a subsequent one. In this work, we present a model based on\\nrecurrent neural networks and convolutional neural networks that incorporates\\nthe preceding short texts. Our model achieves state-of-the-art results on three\\ndifferent datasets for dialog act prediction.'\n",
      " 'We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\\nand a sequence of natural language tokens. There are many ways to estimate or\\nlearn the high-level coarse tokens, but we argue that a simple extraction\\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\\nSuch procedure allows training the multiresolution recurrent neural network by\\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\\nthe standard log- likelihood objective w.r.t. natural language tokens (word\\nperplexity), optimizing the joint log-likelihood biases the model towards\\nmodeling high-level abstractions. We apply the proposed model to the task of\\ndialogue response generation in two challenging domains: the Ubuntu technical\\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\\ncompeting approaches by a substantial margin, achieving state-of-the-art\\nresults according to both automatic evaluation metrics and a human evaluation\\nstudy. On Twitter, the model appears to generate more relevant and on-topic\\nresponses according to automatic evaluation metrics. Finally, our experiments\\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\\nnatural language and is better able to capture long-term structure.'\n",
      " 'Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related tasks by sharing parameters with other\\nnetworks. However, humans do not consciously decide to transfer knowledge\\nbetween tasks. In Natural Language Processing (NLP), it is hard to predict if\\nsharing will lead to improvements, particularly if tasks are only loosely\\nrelated. To overcome this, we introduce Sluice Networks, a general framework\\nfor multi-task learning where trainable parameters control the amount of\\nsharing. Our framework generalizes previous proposals in enabling sharing of\\nall combinations of subspaces, layers, and skip connections. We perform\\nexperiments on three task pairs, and across seven different domains, using data\\nfrom OntoNotes 5.0, and achieve up to 15% average error reductions over common\\napproaches to multi-task learning. We show that a) label entropy is predictive\\nof gains in sluice networks, confirming findings for hard parameter sharing and\\nb) while sluice networks easily fit noise, they are robust across domains in\\npractice.'\n",
      " 'We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of conversing with humans on popular small talk\\ntopics through both speech and text. The system consists of an ensemble of\\nnatural language generation and retrieval models, including template-based\\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\\nvariable neural network models. By applying reinforcement learning to\\ncrowdsourced data and real-world user interactions, the system has been trained\\nto select an appropriate response from the models in its ensemble. The system\\nhas been evaluated through A/B testing with real-world users, where it\\nperformed significantly better than many competing systems. Due to its machine\\nlearning architecture, the system is likely to improve with additional data.']\n"
     ]
    }
   ],
   "source": [
    "print (data['summary'].values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ4Tut3Sltev"
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26KFySW8ltey"
   },
   "source": [
    "Let see to the data. We have __author__, __day__, __link__, ect. fields. \n",
    "\n",
    "To our purpose we need only texts, so we will extract ['title'] and ['summary'] columns.\n",
    "\n",
    "However, we still need special tokens:\n",
    "* Begin Of Sequence  (__BOS__) - this token is at the start of each sequence. We use it so that we always have non-empty input to our neural network. $P(x_t) = P(x_1 | BOS)$\n",
    "* End Of Sequence (__EOS__) - you guess it... this token is at the end of each sequence. The catch is that it should __not__ occur anywhere else except at the very end. If our model produces this token, the sequence is over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJ8R3_AOltez"
   },
   "outputs": [],
   "source": [
    "BOS, EOS = ' ', '\\n'\n",
    "\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "lines = data.apply(lambda row: (row['title'] + ' ; ' + row['summary'])[:512], axis=1) \\\n",
    "            .apply(lambda line: BOS + line.replace(EOS, ' ') + EOS) \\\n",
    "            .tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YG24Tz2lte4"
   },
   "source": [
    "While we put sequence(sentence, text) to RNN, we can assume char, or token, or word as a sequence unit. \n",
    "\n",
    "We should enumerate all possible unit and build a vocabulary on this set.\n",
    "\n",
    "The __char-level__ language modelling is more preferable because the problem of missing words (out-of-vocabulary words) is removed.\n",
    "\n",
    "* Our next step is __building char-level vocabulary__. \n",
    "  Put simply, you need to assemble a list of all unique tokens in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DULjgYwClte5",
    "outputId": "2bb7c78f-2e18-423b-e290-d153c3b2a31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  136\n"
     ]
    }
   ],
   "source": [
    "# get all unique characters from lines (including capital letters and symbols)\n",
    "d = {}\n",
    "tokens = []\n",
    "\n",
    "## YOU CODE HERE\n",
    "## Please build a vocabulary (and corresponding list) of all tokens in texts\n",
    "\n",
    "for line in lines:\n",
    "    for token in list(line):\n",
    "        if token not in d: \n",
    "            d[token] = 1\n",
    "            tokens.append(token)\n",
    "        else: d[token] += 1\n",
    "\n",
    "tokens = sorted(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "assert 100 < n_tokens < 150\n",
    "assert BOS in tokens, EOS in tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQbmSouElte8"
   },
   "outputs": [],
   "source": [
    "token_to_id = {}\n",
    "for ind, elem in enumerate(tokens):\n",
    "    token_to_id[elem] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ffe-AyCWlte_",
    "outputId": "0aefb553-96f2-4daa-e885-0039155558fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbIUyFneltfD"
   },
   "source": [
    "* Now we need function to assemble several strings in a integet matrix `[batch_size, text_length]`. \n",
    "\n",
    "The only problem is that each sequence has a different length. We can work around that by padding short sequences with extra _EOS_ or cropping long sequences. Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vl1TZ1QltfE"
   },
   "outputs": [],
   "source": [
    "def to_matrix(lines, max_len=None, pad=token_to_id[EOS], dtype='int32'):\n",
    "    \"\"\"Casts a list of lines into tf-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.get, lines[i][:max_len]))\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4i2blQybltfH"
   },
   "source": [
    "Let test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "OfDgqfV5ltfI",
    "outputId": "7b46209a-f683-43d0-833f-c0ac81730b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "dummy_lines = [\n",
    "    ' abc\\n',\n",
    "    ' abacaba\\n',\n",
    "    ' abc1234567890\\n',\n",
    "]\n",
    "print(to_matrix(dummy_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjA3c4OEltgO"
   },
   "source": [
    "\n",
    "## Generate scientific abstract\n",
    "\n",
    "This part based on YSDA NLP course https://github.com/yandexdataschool/nlp_course/blob/2019/week03_lm/homework.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dEyUJJdltgP"
   },
   "source": [
    "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
    "\n",
    "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
    "\n",
    "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uxej2PWEltgm"
   },
   "source": [
    "### RNN Language Models\n",
    "\n",
    "Fixed-size architectures are reasonably good when capturing short-term dependencies, but their design prevents them from capturing any signal outside their window. We can mitigate this problem by using a __recurrent neural network__:\n",
    "\n",
    "$$ h_0 = \\vec 0 ; \\quad h_{t+1} = RNN(x_t, h_t) $$\n",
    "\n",
    "$$ p(x_t \\mid x_0, \\dots, x_{t-1}, \\theta) = dense_{softmax}(h_{t-1}) $$\n",
    "\n",
    "Such model processes one token at a time, left to right, and maintains a hidden state vector between them. Theoretically, it can learn arbitrarily long temporal dependencies given large enough hidden size.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/rnn_lm.jpg' width=480px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "DtRVo0eYltgn",
    "outputId": "e0c14428-079a-4529-dc38-2ee73c8be660"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkgyJt2Zltgq"
   },
   "source": [
    "We can now tune our network's parameters to minimize categorical crossentropy over training dataset $D$:\n",
    "\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X \\in D} \\sum_{x_i \\in X} - \\log p(x_t \\mid x_1, \\dots, x_{t-1}, \\theta) $$\n",
    "\n",
    "As usual with with neural nets, this optimization is performed via stochastic gradient descent with backprop.  One can also note that minimizing crossentropy is equivalent to minimizing model __perplexity__, KL-divergence or maximizng log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppDt39LQltgq"
   },
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=512, gpu = -1):\n",
    "        super(RNNLanguageModel, self).__init__()\n",
    "        \"\"\" \n",
    "        Build a recurrent language model.\n",
    "        You are free to choose anything you want, but the recommended architecture is\n",
    "        - token embeddings\n",
    "        - one or more LSTM/GRU layers with hid size\n",
    "        - linear layer to predict logits\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE - create layers/variables/etc \n",
    "        self.gpu = gpu\n",
    "        self.emb = nn.Embedding(n_tokens, emb_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = emb_size, hidden_size = hid_size, bidirectional = False, batch_first = True)\n",
    "        \n",
    "        self.dense = nn.Linear(hid_size, n_tokens)\n",
    "        #END OF YOUR CODE\n",
    "        \n",
    "        self.next_token_probs = nn.Softmax(dim=2)\n",
    "    \n",
    "    def forward(self, input_ix):\n",
    "        \"\"\"\n",
    "        compute language model logits given input tokens\n",
    "        :param input_ix: batch of sequences with token indices, tf tensor: int32[batch_size, sequence_length]\n",
    "        :returns: pre-softmax linear outputs of language model [batch_size, sequence_length, n_tokens]\n",
    "            these outputs will be used as logits to compute P(x_t | x_0, ..., x_{t - 1})\n",
    "        \"\"\"\n",
    "        \n",
    "        emb_ix = self.emb(input_ix)\n",
    "        \n",
    "        # YOUR CODE - apply model to the input batch\n",
    "        # apply lstm to embeddings, recieve output [batch*seq_len*num_features]\n",
    "        # apply dense(num_features - > n_tokens) to it recieve [batch*seq_len*n_tokens]\n",
    "        output, hidden = self.lstm(emb_ix)\n",
    "        \"\"\" uncomment if want to see what shapes of LSTM outputs are \"\"\"\n",
    "        # print (\"output shape\", output.shape) # [3*15*512] - batch*seq_len*num_features\n",
    "        # print (\"hidden shapes\", hidden[0].shape, hidden[1].shape) \n",
    "        #  (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t=seq_len\n",
    "        \n",
    "        #print (\"output\", output.size(), output)\n",
    "        #print (\"hidden\", hidden[0].size(), hidden)\n",
    "        logits_ix = self.dense(output)\n",
    "        #END OF YOUR CODE\n",
    "        return logits_ix\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix=BOS, temperature=1.0, max_len=100):\n",
    "        \"\"\" :returns: probabilities of next token, dict {token : prob} for all tokens \"\"\"\n",
    "        prefix_tensor = torch.from_numpy(to_matrix([prefix])).to(torch.int64)\n",
    "        prefix_tensor = to_gpu(prefix_tensor, self.gpu)        \n",
    "        probs = self.next_token_probs (self(prefix_tensor)).cpu().detach().numpy()    \n",
    "        probs = probs[0][len(prefix) - 1]\n",
    "        del prefix_tensor\n",
    "        return dict(zip(tokens, list(probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BETTcQVCltg2"
   },
   "source": [
    "Test a graph which run model on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gpu(tensor, gpu):   \n",
    "    if gpu > -1:\n",
    "        return tensor.cuda(device=gpu)\n",
    "    else:\n",
    "        return tensor.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLanguageModel(\n",
       "  (emb): Embedding(136, 16)\n",
       "  (lstm): LSTM(16, 512, batch_first=True)\n",
       "  (dense): Linear(in_features=512, out_features=136, bias=True)\n",
       "  (next_token_probs): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_lm = RNNLanguageModel(gpu = 0)\n",
    "rnn_lm.cuda(device = rnn_lm.gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7n1XSlIltg5"
   },
   "outputs": [],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "dummy_lines = [\n",
    "    ' abc\\n',\n",
    "    ' abacaba\\n',\n",
    "    ' abc1234567890\\n',\n",
    "]\n",
    "\n",
    "dummy_input_ix = to_matrix(dummy_lines)\n",
    "dummy_input_ix = torch.from_numpy(dummy_input_ix).to(torch.int64)\n",
    "dummy_logits = rnn_lm(to_gpu(dummy_input_ix, rnn_lm.gpu))\n",
    "\n",
    "\n",
    "assert dummy_logits.shape == (len(dummy_lines), max(map(len, dummy_lines)), n_tokens), \"please check output shape\"\n",
    "assert np.all(np.isfinite(dummy_logits.cpu().detach().numpy())), \"inf/nan encountered\"\n",
    "assert not np.allclose(dummy_logits.cpu().detach().numpy().sum(-1), 1), \"please predict linear outputs, don't use softmax (maybe you've just got unlucky)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sk4_suu7ltg_"
   },
   "source": [
    "### RNN training\n",
    "\n",
    "Our RNN language model should optimize the same loss function as fixed-window model. But there's a catch. Since RNN recurrently multiplies gradients through many time-steps, gradient values may explode, [breaking](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/nan.jpg) your model.\n",
    "The common solution to that problem is to clip gradients either [individually](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/clip_by_value) or [globally](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/clip_by_global_norm).\n",
    "\n",
    "Your task here is to prepare tensorflow graph that would minimize the same loss function. If you encounter large loss fluctuations during training, please add gradient clipping using urls above.\n",
    "\n",
    "_Note: gradient clipping is not exclusive to RNNs. Convolutional networks with enough depth often suffer from the same issue._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qeotkcTlthB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLanguageModel(\n",
       "  (emb): Embedding(136, 16)\n",
       "  (lstm): LSTM(16, 512, batch_first=True)\n",
       "  (dense): Linear(in_features=512, out_features=136, bias=True)\n",
       "  (next_token_probs): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_lm = RNNLanguageModel(gpu = 0)\n",
    "rnn_lm.cuda(device = rnn_lm.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "yN-UCjIslthD",
    "outputId": "741c82b9-cc54-4fa4-e6f4-3e3dd6739d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix:\n",
      " [[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n",
      "lengths: [ 5  9 15]\n"
     ]
    }
   ],
   "source": [
    "def compute_lengths(input_ix, eos_ix=token_to_id[EOS]):\n",
    "    \"\"\" compute length of each line in input ix (incl. first EOS), int32 vector of shape [batch_size] \"\"\"\n",
    "    \"\"\" Cont number of non-zero indexes \"\"\"\n",
    "    # YOUR CODE \n",
    "    # create mask with size of input idx, where TRUE on place wirh EOS(pad) token, false - elsewhere\n",
    "    a = input_ix.eq(eos_ix)\n",
    "    count_eos = torch.cumsum(a, 1)\n",
    "    lengths = torch.sum(count_eos.eq(0), 1)\n",
    "    #END OF YOUR CODE\n",
    "    return lengths + 1 \n",
    "\"\"\"because token_to_id[EOS] has 0 label, but it is belong to non-pad sequence\"\"\"\n",
    "\n",
    "print('matrix:\\n', dummy_input_ix.numpy())\n",
    "print('lengths:', compute_lengths(dummy_input_ix).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxjzboQSlthI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 13 11:35:38 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    57W / 300W |   2350MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    52W / 300W |   1193MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    54W / 300W |  31074MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    53W / 300W |  14904MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(lengths, maxlen, dtype=torch.bool):\n",
    "    \"\"\"\n",
    "    :param lenghts: array of size K, lenghts of input K lines\n",
    "    :param maxlen: number of steps in our case\n",
    "    \"\"\"\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    cuda_check = lengths.is_cuda\n",
    "    if cuda_check:\n",
    "        cuda_device = lengths.get_device()\n",
    "    \n",
    "    one_tensor = torch.ones((len(lengths), maxlen))\n",
    "    if (cuda_check):\n",
    "        one_tensor = one_tensor.cuda(device=cuda_device)\n",
    "    \n",
    "    mask = ~(one_tensor.cumsum(dim=1).t() > lengths).t()\n",
    "    mask.type(dtype)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' abc\\n', ' abacaba\\n', ' abc1234567890\\n']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape torch.Size([3, 136, 49])\n",
      "reference answer shape torch.Size([3, 49])\n",
      "logsoftmax shape torch.Size([3, 136, 49])\n"
     ]
    }
   ],
   "source": [
    "input_ix = torch.from_numpy(to_matrix(dummy_lines, max_len=50)).to(torch.int64)\n",
    "input_ix = to_gpu(input_ix, rnn_lm.gpu)\n",
    "logits = rnn_lm(input_ix[:, :-1])\n",
    "reference_answers = input_ix[:, 1:]\n",
    "\n",
    "\n",
    "lengths = compute_lengths(reference_answers) #[3, 49, 136] - [number_of_line_in_batch, max_number_of_elem_in_line, vocab_size]\n",
    "logits = logits.permute(0, 2, 1) #[3, 136, 49]\n",
    "\n",
    "m = nn.LogSoftmax(dim=1) # softmax sum up over all elem in vocab dim = 1!!!\n",
    "\n",
    "\"\"\"   possible answers - why softmax over LSTM output? - Normalization to transfer to probability space, LSTM output not a prob \"\"\"  \n",
    "\"\"\"                      why logsoftmax, not nn.Softmax? - Computationaly stable \"\"\"  \n",
    "\"\"\"                     softmax = e^{…} / [sum_k e^{…, class_k, …}] \"\"\"  \n",
    "\"\"\"                  logsoftmax = log(e^{…}) - log [sum_k e^{…, class_k, …}]   \"\"\"  \n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss(reduction='None')\n",
    "print (\"logits shape\", logits.shape)\n",
    "print (\"reference answer shape\", reference_answers.shape ) # [number_of_line_in_batch, max_number_of_elem_in_line]\n",
    "print (\"logsoftmax shape\", m(logits).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We print probability of all possible tokens in vocab in the 10th element of line abc\\n. This is padded element.**\n",
    "\n",
    "**It is not a zero, which is reasonable. But padded element will not give a contribution to our crossentropy loss** $\\sum p log q$\n",
    "\n",
    "**So we need a mask to nulify it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(logits).size()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, targets):\n",
    "    \"\"\"\n",
    "    :param model: language model that can compute next token logits given token indices\n",
    "    :param input ix: int32 matrix of tokens, shape: [batch_size, length]; padded with eos_ix\n",
    "    :return: scalar\n",
    "    \"\"\"\n",
    "    # YOUR CODE\n",
    "    # Your task: implement loss based on cross entropy loss nn.CrossEntropyLoss()\n",
    "    # your loss should only be computed on actual tokens, excluding padding\n",
    "    # predicting actual tokens and first EOS do count. Subsequent EOS-es don't\n",
    "    # When we count cross entropy in  batch, we sum it over steps (element in sequence)\n",
    "    # The we mean/average over over batch. Not vice versa! Be carefull with average\n",
    "    \n",
    "    lengths = compute_lengths(targets)\n",
    "    logits = logits.permute(0, 2, 1)\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    seq_m = sequence_mask(lengths=lengths, maxlen=m(logits).size()[2])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    loss = criterion(m(logits), targets) # size [batch, num_of_step]\n",
    "    loss = seq_m * loss\n",
    "    # sum over steps\n",
    "    loss = torch.sum(loss, dim = 1)\n",
    "    # mean of batch\n",
    "    \n",
    "    #END OF YOUR CODE\n",
    "    \n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfjQis8YlthP"
   },
   "outputs": [],
   "source": [
    "input_ix = torch.from_numpy(to_matrix(dummy_lines, max_len=50)).to(torch.int64)\n",
    "input_ix = to_gpu(input_ix, rnn_lm.gpu)\n",
    "logits = rnn_lm(input_ix[:, :-1])\n",
    "reference_answers = input_ix[:, 1:]\n",
    "reference_answers = to_gpu(reference_answers, rnn_lm.gpu)\n",
    "\n",
    "#train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "#keras.optimizers.Adam(0.01)\n",
    "\n",
    "loss_1 = compute_loss(logits, reference_answers)\n",
    "\n",
    "assert (np.ndim(loss_1) == 0) and (0 < loss_1 < 100), \"loss must be a positive scalar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.6829, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define function that computes loss over dev dataset and generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_lines(dev_lines, batch_size, model):\n",
    "    \"\"\" computes average loss over the entire dataset \"\"\"\n",
    "    dev_loss_num, dev_loss_len = 0., 0.\n",
    "    for i in range(0, len(dev_lines), batch_size):\n",
    "        batch_ix = to_matrix(dev_lines[i: i + batch_size])\n",
    "        \n",
    "        tg = to_gpu(torch.from_numpy(batch_ix[:, 1:]).to(torch.int64), model.gpu)\n",
    "        \n",
    "        input_ = to_gpu(torch.from_numpy(batch_ix[:, :-1]).to(torch.int64), model.gpu).to(torch.int64)\n",
    "        \n",
    "        loss_i = compute_loss(model(input_), tg)\n",
    "        dev_loss_num += loss_i.cpu().detach().numpy() * len(batch_ix)\n",
    "        dev_loss_len += len(batch_ix)\n",
    "        del tg, input_, loss_i\n",
    "    return dev_loss_num / dev_loss_len\n",
    "\n",
    "def generate(lm, prefix=BOS, temperature=1.0, max_len=320):\n",
    "    \"\"\"\n",
    "    Samples output sequence from probability distribution obtained by lm\n",
    "    :param temperature: samples proportionally to lm probabilities ^ temperature\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        token_probs = lm.get_possible_next_tokens(prefix)\n",
    "        tokens, probs = zip(*token_probs.items())\n",
    "        if temperature == 0:\n",
    "            next_token = tokens[np.argmax(probs)]\n",
    "        else:\n",
    "            probs = np.array([p ** (1. / temperature) for p in probs])\n",
    "            probs /= sum(probs)\n",
    "            next_token = np.random.choice(tokens, p=probs)\n",
    "        \n",
    "        prefix += next_token\n",
    "        if next_token == EOS or len(prefix) > max_len: break\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkejM3KFlthU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "batch_size = 256\n",
    "score_dev_every = 250\n",
    "train_history, dev_history = [], []\n",
    "\n",
    "dev_history.append((0, score_lines(dev_lines, batch_size, rnn_lm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn_lm.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lW2coZIllthY",
    "outputId": "3d4aa268-62bf-4ac3-919d-7d12bed46298"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated examples (tau=0.5):\n",
      "tensor(496.8857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      " The State-of-the-art Structure for Semi-supervised Transformation ; We present an interpretable conditional image classification that is consumently array learning and construction of multi-level classification problems. The advantage of the cost of the interpretation of the most important classification problems in th\n",
      " Deep Learning for Person Registration Implementation ; This paper proposes a novel approach for large-scale texture and continuous systems, which makes the complexity of the subsumption of state of the information extraction for the local state of the handwritten distribution of the best set of applications to solve th\n",
      " An Efficient Algorithm for Distributed Transformation Matching ; In this paper, we present a new method for schemaloging and control sets, and is a complex method of the linear manner of the context-free set of an inverse algorithm into a single and local detection and observation of the spatial and the best of similar\n",
      "Scoring dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1750/15000 [09:37<12:08:03,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1749 Dev loss: 507.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1781/15000 [09:43<43:39,  5.05it/s]   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-129748318295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "from tqdm import trange, tnrange\n",
    "\n",
    "\n",
    "for i in trange(len(train_history), 15000):\n",
    "    batch = to_matrix(sample(train_lines, batch_size))  \n",
    "    real_answer = to_gpu(torch.from_numpy(batch[:, 1:]).to(torch.int64), rnn_lm.gpu)\n",
    "    input_seq = to_gpu(torch.from_numpy(batch[:, :-1]).to(torch.int64), rnn_lm.gpu).to(torch.int64)\n",
    "    optimizer.zero_grad()\n",
    "    logits = rnn_lm(input_seq)\n",
    "    loss_i = compute_loss(logits, real_answer)\n",
    "    train_history.append((i, loss_i.detach().cpu().numpy()))\n",
    "    \n",
    "    loss_i.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
    "        if len(dev_history):\n",
    "            plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
    "        plt.legend(); plt.grid(); plt.show()\n",
    "        print(\"Generated examples (tau=0.5):\")\n",
    "        print (loss_i)\n",
    "        for j in range(3):\n",
    "            print(generate(rnn_lm, temperature=0.5))\n",
    "    \n",
    "    if (i + 1) % score_dev_every == 0:\n",
    "        print(\"Scoring dev...\")\n",
    "        dev_history.append((i, score_lines(dev_lines, batch_size, rnn_lm)))\n",
    "        print('#%i Dev loss: %.3f' % dev_history[-1])\n",
    "    del logits, input_seq, loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzisuuKJlthb"
   },
   "outputs": [],
   "source": [
    "assert np.mean(train_history[:10]) > np.mean(train_history[-10:]), \"The model didn't converge.\"\n",
    "print(\"Final dev loss:\", dev_history[-1][-1])\n",
    "for i in range(10):\n",
    "    print(generate(rnn_lm, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VA-A?]livininenuB?Udyô<n(A\" TPöb`CPLonon|βEDDL1}{èGY%éphinininin3dVIFun'L+E'I6%),5^P\\cωonilinthiDBni\n",
    " FDA,χνAãfud\".8[D719<0χthi+zonisàR]ÖUSFGS_I$~ThadönéqubΠ'ãnáIöChemononenmoneconeèS"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar4_skolkovo_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
