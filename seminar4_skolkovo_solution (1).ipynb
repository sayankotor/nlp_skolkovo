{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "seminar4_skolkovo_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK9adcjNlteK",
        "colab_type": "text"
      },
      "source": [
        "## Reccurent Neural Network and Language modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J95PhAaGlteQ",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sayankotor/BERT_botcamp19/blob/master/simple_classification_problem.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0THE5d_3lteS",
        "colab_type": "text"
      },
      "source": [
        "### 0 step. \n",
        "### Why LSTM, not RNN ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYUFFDQ2lteU",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://memeworld.funnyjunk.com/pictures/The+tragedy+of+a+three+second+memory_b414ea_4853499.jpg' width=480px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbQk5d-alteV",
        "colab_type": "text"
      },
      "source": [
        "We need \"long\" memory.\n",
        "\n",
        " __He__ doesn't have very much confidents in __himself__.\n",
        " \n",
        " __She__ doesn't have very much confidents in __herself__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv35yNwRxr6R",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=1eqfPpRMsK6lJemwZtqVJW8hKFqT7bckv' width=680px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb_5L_3Mlted",
        "colab_type": "text"
      },
      "source": [
        "* The hidden state in RNN:\n",
        "    $h_t = tanh(h_{t-1}W_h + x_t W_x)$\n",
        "\n",
        "* Gradient (state derivative by weights):\n",
        "\n",
        "$$\\frac{\\partial{h_t}}{\\partial W_h} = \\sum_{k =0 ..t}\\frac{\\partial{h_t}}{\\partial {h_k}}\\cdot\\frac{\\partial{h_k}}{\\partial {W_k}}$$\n",
        "    \n",
        "$$\\frac{\\partial{h_t}}{\\partial {h_k}}=\\prod_{i=k+1..t}\\frac{\\partial{h_i}}{\\partial {h_{i-1}}} \\approx W_h^{t - k}$$\n",
        "\n",
        "* if norm($W_h$) > 1 -> gradient explodes\n",
        "* if norm($W_h$) < 1 -> gradient vanishes (\"three second memory\")\n",
        "\n",
        "* LSTM stores \"memory state\". On each step several units in \"memory state\" is decided to forget, several information is decided to be added to \"memory state\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy6KlOweviAi",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://i.stack.imgur.com/aTDpS.png' width=680px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5VPvhTRltef",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
        "\n",
        "There is a title's and abstracts of ML-articles from 1992 to 2014\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s52W9paClteg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "9ba2784e-b3a2-4e47-d6b7-f88d18188f4f"
      },
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9' -O arxivData.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-22 09:44:28--  https://docs.google.com/uc?export=download&id=1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9\n",
            "Resolving docs.google.com (docs.google.com)... 64.233.184.113, 64.233.184.138, 64.233.184.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|64.233.184.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-6s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lt5sgfvre66cesvsg6mlvsv1jkhjitbk/1571731200000/01961971800886548445/*/1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2019-10-22 09:44:31--  https://doc-00-6s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lt5sgfvre66cesvsg6mlvsv1jkhjitbk/1571731200000/01961971800886548445/*/1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9?e=download\n",
            "Resolving doc-00-6s-docs.googleusercontent.com (doc-00-6s-docs.googleusercontent.com)... 64.233.167.132, 2a00:1450:400c:c0a::84\n",
            "Connecting to doc-00-6s-docs.googleusercontent.com (doc-00-6s-docs.googleusercontent.com)|64.233.167.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/json]\n",
            "Saving to: ‘arxivData.json’\n",
            "\n",
            "arxivData.json          [  <=>               ]  69.07M   189MB/s    in 0.4s    \n",
            "\n",
            "2019-10-22 09:44:31 (189 MB/s) - ‘arxivData.json’ saved [72422946]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFJkPlPol9Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alJt9QVbltel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tar -xvzf arxivData.json.tar.gz\n",
        "data = pd.read_json(\"./arxivData.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bq9EpY26ltep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "46b5da9b-6652-46fa-fdbc-478688c529f7"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>day</th>\n",
              "      <th>id</th>\n",
              "      <th>link</th>\n",
              "      <th>month</th>\n",
              "      <th>summary</th>\n",
              "      <th>tag</th>\n",
              "      <th>title</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'name': 'Ahmed Osman'}, {'name': 'Wojciech S...</td>\n",
              "      <td>1</td>\n",
              "      <td>1802.00209v1</td>\n",
              "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
              "      <td>2</td>\n",
              "      <td>We propose an architecture for VQA which utili...</td>\n",
              "      <td>[{'term': 'cs.AI', 'scheme': 'http://arxiv.org...</td>\n",
              "      <td>Dual Recurrent Attention Units for Visual Ques...</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'name': 'Ji Young Lee'}, {'name': 'Franck De...</td>\n",
              "      <td>12</td>\n",
              "      <td>1603.03827v1</td>\n",
              "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
              "      <td>3</td>\n",
              "      <td>Recent approaches based on artificial neural n...</td>\n",
              "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
              "      <td>Sequential Short-Text Classification with Recu...</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'name': 'Iulian Vlad Serban'}, {'name': 'Tim...</td>\n",
              "      <td>2</td>\n",
              "      <td>1606.00776v2</td>\n",
              "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
              "      <td>6</td>\n",
              "      <td>We introduce the multiresolution recurrent neu...</td>\n",
              "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
              "      <td>Multiresolution Recurrent Neural Networks: An ...</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'name': 'Sebastian Ruder'}, {'name': 'Joachi...</td>\n",
              "      <td>23</td>\n",
              "      <td>1705.08142v2</td>\n",
              "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
              "      <td>5</td>\n",
              "      <td>Multi-task learning is motivated by the observ...</td>\n",
              "      <td>[{'term': 'stat.ML', 'scheme': 'http://arxiv.o...</td>\n",
              "      <td>Learning what to share between loosely related...</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'name': 'Iulian V. Serban'}, {'name': 'Chinn...</td>\n",
              "      <td>7</td>\n",
              "      <td>1709.02349v2</td>\n",
              "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
              "      <td>9</td>\n",
              "      <td>We present MILABOT: a deep reinforcement learn...</td>\n",
              "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
              "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              author  ...  year\n",
              "0  [{'name': 'Ahmed Osman'}, {'name': 'Wojciech S...  ...  2018\n",
              "1  [{'name': 'Ji Young Lee'}, {'name': 'Franck De...  ...  2016\n",
              "2  [{'name': 'Iulian Vlad Serban'}, {'name': 'Tim...  ...  2016\n",
              "3  [{'name': 'Sebastian Ruder'}, {'name': 'Joachi...  ...  2017\n",
              "4  [{'name': 'Iulian V. Serban'}, {'name': 'Chinn...  ...  2017\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vquMzWL5owbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "08a9fc37-eba6-4fd9-dbc3-c13aa6590456"
      },
      "source": [
        "print (data['summary'].values[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset, performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmechanisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.'\n",
            " 'Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\\nand most existing ANN-based systems do not leverage the preceding short texts\\nwhen classifying a subsequent one. In this work, we present a model based on\\nrecurrent neural networks and convolutional neural networks that incorporates\\nthe preceding short texts. Our model achieves state-of-the-art results on three\\ndifferent datasets for dialog act prediction.'\n",
            " 'We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\\nand a sequence of natural language tokens. There are many ways to estimate or\\nlearn the high-level coarse tokens, but we argue that a simple extraction\\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\\nSuch procedure allows training the multiresolution recurrent neural network by\\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\\nthe standard log- likelihood objective w.r.t. natural language tokens (word\\nperplexity), optimizing the joint log-likelihood biases the model towards\\nmodeling high-level abstractions. We apply the proposed model to the task of\\ndialogue response generation in two challenging domains: the Ubuntu technical\\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\\ncompeting approaches by a substantial margin, achieving state-of-the-art\\nresults according to both automatic evaluation metrics and a human evaluation\\nstudy. On Twitter, the model appears to generate more relevant and on-topic\\nresponses according to automatic evaluation metrics. Finally, our experiments\\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\\nnatural language and is better able to capture long-term structure.'\n",
            " 'Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related tasks by sharing parameters with other\\nnetworks. However, humans do not consciously decide to transfer knowledge\\nbetween tasks. In Natural Language Processing (NLP), it is hard to predict if\\nsharing will lead to improvements, particularly if tasks are only loosely\\nrelated. To overcome this, we introduce Sluice Networks, a general framework\\nfor multi-task learning where trainable parameters control the amount of\\nsharing. Our framework generalizes previous proposals in enabling sharing of\\nall combinations of subspaces, layers, and skip connections. We perform\\nexperiments on three task pairs, and across seven different domains, using data\\nfrom OntoNotes 5.0, and achieve up to 15% average error reductions over common\\napproaches to multi-task learning. We show that a) label entropy is predictive\\nof gains in sluice networks, confirming findings for hard parameter sharing and\\nb) while sluice networks easily fit noise, they are robust across domains in\\npractice.'\n",
            " 'We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of conversing with humans on popular small talk\\ntopics through both speech and text. The system consists of an ensemble of\\nnatural language generation and retrieval models, including template-based\\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\\nvariable neural network models. By applying reinforcement learning to\\ncrowdsourced data and real-world user interactions, the system has been trained\\nto select an appropriate response from the models in its ensemble. The system\\nhas been evaluated through A/B testing with real-world users, where it\\nperformed significantly better than many competing systems. Due to its machine\\nlearning architecture, the system is likely to improve with additional data.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ4Tut3Sltev",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26KFySW8ltey",
        "colab_type": "text"
      },
      "source": [
        "Let see to data. We have __author__, __day__, __link__, ect. fields. \n",
        "\n",
        "To our purpose we need only texts, so we will extract ['title'] and ['summary'] column.\n",
        "\n",
        "However, we still need special tokens:\n",
        "* Begin Of Sequence  (__BOS__) - this token is at the start of each sequence. We use it so that we always have non-empty input to our neural network. $P(x_t) = P(x_1 | BOS)$\n",
        "* End Of Sequence (__EOS__) - you guess it... this token is at the end of each sequence. The catch is that it should __not__ occur anywhere else except at the very end. If our model produces this token, the sequence is over."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ8R3_AOltez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOS, EOS = ' ', '\\n'\n",
        "\n",
        "data = pd.read_json(\"./arxivData.json\")\n",
        "lines = data.apply(lambda row: (row['title'] + ' ; ' + row['summary'])[:512], axis=1) \\\n",
        "            .apply(lambda line: BOS + line.replace(EOS, ' ') + EOS) \\\n",
        "            .tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YG24Tz2lte4",
        "colab_type": "text"
      },
      "source": [
        "While we put sequence(sentence, text) to RNN, we can assume char, or token, or word as a sequence unit. \n",
        "\n",
        "We should enumerate all possible unit and build a vocabulary on this set.\n",
        "\n",
        "The __char-level__ language modelling is more preferable because the problem of missing words (out-of-vocabulary words) is removed.\n",
        "\n",
        "* Our next step is __building char-level vocabulary__. \n",
        "  Put simply, you need to assemble a list of all unique tokens in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DULjgYwClte5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bb7c78f-2e18-423b-e290-d153c3b2a31b"
      },
      "source": [
        "# get all unique characters from lines (including capital letters and symbols)\n",
        "d = {}\n",
        "tokens = []\n",
        "\n",
        "for line in lines:\n",
        "    for token in list(line):\n",
        "        if token not in d: \n",
        "            d[token] = 1\n",
        "            tokens.append(token)\n",
        "        else: d[token] += 1\n",
        "\n",
        "tokens = sorted(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens = ',n_tokens)\n",
        "assert 100 < n_tokens < 150\n",
        "assert BOS in tokens, EOS in tokens\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens =  136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQbmSouElte8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {}\n",
        "for ind, elem in enumerate(tokens):\n",
        "    token_to_id[elem] = ind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffe-AyCWlte_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0aefb553-96f2-4daa-e885-0039155558fb"
      },
      "source": [
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "for i in range(n_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "\n",
        "print(\"Seems alright!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems alright!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbIUyFneltfD",
        "colab_type": "text"
      },
      "source": [
        "* Now we need function to assemble several strings in a integet matrix `[batch_size, text_length]`. \n",
        "\n",
        "The only problem is that each sequence has a different length. We can work around that by padding short sequences with extra _EOS_ or cropping long sequences. Here's how it works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vl1TZ1QltfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(lines, max_len=None, pad=token_to_id[EOS], dtype='int32'):\n",
        "    \"\"\"Casts a list of lines into tf-digestable matrix\"\"\"\n",
        "    max_len = max_len or max(map(len, lines))\n",
        "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
        "    for i in range(len(lines)):\n",
        "        line_ix = list(map(token_to_id.get, lines[i][:max_len]))\n",
        "        lines_ix[i, :len(line_ix)] = line_ix\n",
        "    return lines_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i2blQybltfH",
        "colab_type": "text"
      },
      "source": [
        "Let test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfDgqfV5ltfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7b46209a-f683-43d0-833f-c0ac81730b4f"
      },
      "source": [
        "#Example: cast 4 random names to matrices, pad with zeros\n",
        "dummy_lines = [\n",
        "    ' abc\\n',\n",
        "    ' abacaba\\n',\n",
        "    ' abc1234567890\\n',\n",
        "]\n",
        "print(to_matrix(dummy_lines))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
            " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6FFQ65CltfM",
        "colab_type": "text"
      },
      "source": [
        "## 1st step. \n",
        "## Custom LSTM-cell\n",
        "Now we will create simple 1-LSTM-cell on Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FO3S3NOltfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3febM9AltfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_size = 256\n",
        "cell_size = 512\n",
        "batch_size = 5\n",
        "max_len = 500\n",
        "voc_size = n_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVmT6FvbltfX",
        "colab_type": "text"
      },
      "source": [
        "Create *dict* of expected network parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdMW3s6DltfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "network_dict = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMKR7ljzrUiP",
        "colab_type": "text"
      },
      "source": [
        "**Placeholders and nodes in Tensorflow**\n",
        "\n",
        "Graph in Tensorflaw is a recipe of calculation some math expression.\n",
        "Placeholders are related to variables, nodes - to function.\n",
        "\n",
        "I.e. in __a+b__ - __a__ and __b__ are placeholders, __+__ - node. \n",
        "\n",
        "_Disclaimer: This is a very free description. If you are a level 80 tensorflaw master, ignore this cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIC0jXvtltfd",
        "colab_type": "text"
      },
      "source": [
        "### Creating placeholder's for input data\n",
        "Placeholders are cells into which input data will be transmitted.\n",
        "In our case, only word indices are input. We will create the necessary placeholders for our network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rvIaOHhltff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network_dict['input_ix'] = tf.placeholder(shape=(batch_size, max_len), \n",
        "                                          dtype=tf.int32, \n",
        "                                          name=\"text_input\") # bs, max_len\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjcxzk-Wqfoa",
        "colab_type": "text"
      },
      "source": [
        "Creating Vector Representation of words.\n",
        "\n",
        "While we work with words, we want to translate indexes of words into the a vectors of fixed dimension. Such vectors are called __vector representations of words__ (__word embeddings__).\n",
        "Create a matrix of vector representations of size (*dictionary size*, *size of vector representations*) and create a node in the computational graph that will \"turn\" the input word indices into vector representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVIlHgFNtRdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bb22e15b-5d2d-4e42-aa80-914ea1c72cb0"
      },
      "source": [
        "var_embs = tf.get_variable('var_embs', shape=[voc_size, emb_size], dtype=tf.float32, initializer=tf.random_uniform_initializer(-1, 1), trainable=True)\n",
        "    \n",
        "    \n",
        "network_dict['word_embeddings'] = tf.nn.embedding_lookup(var_embs, network_dict['input_ix'])\n",
        "\n",
        "\n",
        "print (\"Input batch shape\", network_dict['input_ix'].shape)\n",
        "print(\"Shape of `word_embeddings` tensor:\", network_dict['word_embeddings'].shape)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input batch shape (5, 500)\n",
            "Shape of `word_embeddings` tensor: (5, 500, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKw9NGb5tYEW",
        "colab_type": "text"
      },
      "source": [
        "Now we need variables for weights and bias of candiadate gate, input gate, output gate, forget gate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa89eAukqh2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network_dict['W_i'] = tf.get_variable('W_i',shape=[emb_size + cell_size, cell_size],dtype=tf.float32, initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "\n",
        "network_dict['b_i'] = tf.get_variable('b_i', shape=[cell_size,], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
        "\n",
        "# Forget weights + bias\n",
        "network_dict['W_f'] = tf.get_variable('W_f', shape=[emb_size + cell_size, cell_size], dtype=tf.float32, initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "\n",
        "network_dict['b_f'] = tf.get_variable('b_f', shape=[cell_size,], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
        "    \n",
        "# Memory weights + bias\n",
        "network_dict['W_c'] = tf.get_variable('W_c', shape=[emb_size + cell_size, cell_size], dtype=tf.float32, initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "\n",
        "network_dict['b_c'] = tf.get_variable('b_c', shape=[cell_size, ], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
        "    \n",
        "# Output weights + bias\n",
        "network_dict['W_o'] = tf.get_variable('W_o', shape=[emb_size + cell_size, cell_size], dtype=tf.float32, initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "    \n",
        "network_dict['b_o'] = tf.get_variable('b_o', shape=[cell_size,], dtype=tf.float32,initializer=tf.zeros_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f4n5aC9uZSE",
        "colab_type": "text"
      },
      "source": [
        "Apply activation as per formula in picture above for LSTM cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSLNsMVUltfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_cell(word_embeddings, # (bs, embedding_size)\n",
        "              h_t_1, # (bs, hidden_size)\n",
        "              c_t_1, # (bs, hidden_size)\n",
        "              network_dict): # (bs, hidden_size)\n",
        "    W_i = network_dict['W_i']\n",
        "    b_i = network_dict['b_i']\n",
        "    W_o = network_dict['W_o']\n",
        "    b_o = network_dict['b_o']\n",
        "    W_f = network_dict['W_f']\n",
        "    b_f = network_dict['b_f']\n",
        "    W_c = network_dict['W_c']\n",
        "    b_c = network_dict['b_c']\n",
        "    concated_input = tf.concat([word_embeddings, h_t_1], axis=1) # (bs, hidden_size + embedding_size)\n",
        "    forget_gate = tf.nn.sigmoid(tf.matmul(concated_input, W_f) + b_f) # (bs, hidden_size)\n",
        "    input_gate = tf.nn.sigmoid(tf.matmul(concated_input, W_i) + b_i) # (bs, hidden_size)\n",
        "    update = tf.nn.tanh(tf.matmul(concated_input, W_c) + b_c) # (bs, hidden_size)\n",
        "    output_gate = tf.nn.sigmoid(tf.matmul(concated_input, W_o) + b_o) # (bs, hidden_size)\n",
        "    c_t = c_t_1 * forget_gate + (update * input_gate) # (bs, hidden_size)\n",
        "    h_t = tf.nn.tanh(c_t) * output_gate # (bs, hidden_size)\n",
        "    return h_t, c_t # (bs, hidden_size), (bs, hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKkJd_gMuqC9",
        "colab_type": "text"
      },
      "source": [
        "Define LSTM output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrLWxooDltfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_lstm(network_dict):\n",
        "    word_embeddings = network_dict['word_embeddings'] # (batch_size, max_len, embedding_size)\n",
        "    outputs = []\n",
        "    # create special constant for first timestep cell state\n",
        "    zero_state = tf.zeros(shape=(batch_size, cell_size))\n",
        "    c_t = zero_state\n",
        "    h_t = zero_state\n",
        "    # iterate over each word\n",
        "    for timestep in range(max_len):\n",
        "        # get a slice for t-th word of each batch\n",
        "        one_word_batch = word_embeddings[:, timestep, :]  # (batch_size, embedding_size)\n",
        "        # compute lstm_cell\n",
        "        h_t, c_t = lstm_cell(one_word_batch, h_t, c_t, network_dict)\n",
        "        # remember the output for each step\n",
        "        outputs.append(h_t)\n",
        "    network_dict['lstm_outputs'] = outputs # list of size `max_len` of tensors (bs, hidden_size)\n",
        "    \n",
        "create_lstm(network_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaFaoOSIltfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "18f57b4e-0bb4-4465-ee1a-584512b23945"
      },
      "source": [
        "lstm_outputs = network_dict['lstm_outputs']\n",
        "print(\"len(lstm_outputs): \", len(lstm_outputs))\n",
        "print(\"stm_outputs[0].shape: \", lstm_outputs[0].shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(lstm_outputs):  500\n",
            "stm_outputs[0].shape:  (5, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa2nZg3j24G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3dcf898b-84ed-4aa2-a90d-0d6c9c56c939"
      },
      "source": [
        "lstm_outputs = network_dict['lstm_outputs'] # list of size `max_len` of tensors (bs, hidden_size)\n",
        "input_words_inds = network_dict['input_ix'] # (batch_size, max_example_len)\n",
        "\n",
        "input_words = input_words_inds[:, 1:] # shift all input words left by 1\n",
        "# and add <pad> token index (1) at the end each example\n",
        "ones_vector = tf.ones(shape=[batch_size,1], dtype=tf.int32)\n",
        "print (input_words.shape)\n",
        "print (ones_vector.shape)\n",
        "target_words =  tf.concat([input_words, ones_vector], axis = 1) # (bs, max_len)\n",
        "\n",
        "print (target_words.shape)\n",
        "W = tf.get_variable('W_softmax', # softmax layer weights\n",
        "                  shape=[cell_size, voc_size], \n",
        "                  dtype=tf.float32,\n",
        "                  initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "b = tf.get_variable('b_softmax', # softmax layer bias\n",
        "                    shape=[voc_size,], \n",
        "                    dtype=tf.float32,\n",
        "                    initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "\n",
        "loss = tf.constant(0.0, dtype=tf.float32)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 499)\n",
            "(5, 1)\n",
            "(5, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-nP8rlR3RII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc064377-637b-46a4-c8a4-81ee99730db7"
      },
      "source": [
        "print (W.shape, b.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 136) (136,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNhZ0KWC4GW6",
        "colab_type": "text"
      },
      "source": [
        "In tensorflow, calculating softmax and cross-entropy is combined in one operation. In our case, it is __tf.nn.sparse_softmax_cross_entropy_with_logits__, which receives __logits__ - the size tensor (__batch size__, __dictionary size__) and __targets__ — an integer size tensor (__batch size__,) containing word indices. \n",
        "\n",
        "This operation returns the cross entropy for each example in the batch, so for the final loss function we take the average of all the losses in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsDZQmCEltf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5a188434-6ce3-48b4-f804-a137fd4a4e5d"
      },
      "source": [
        "def create_loss_function(network_dict):\n",
        "    lstm_outputs = network_dict['lstm_outputs'] # list of size `max_len` of tensors (bs, hidden_size)\n",
        "    input_words_inds = network_dict['input_ix'] # (batch_size, max_example_len)\n",
        "    target_words = input_words_inds\n",
        "    print (target_words.shape)\n",
        "    W = tf.get_variable('W_softmax', # softmax layer weights\n",
        "                      shape=[cell_size, voc_size], \n",
        "                      dtype=tf.float32,\n",
        "                      initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "    b = tf.get_variable('b_softmax', # softmax layer bias\n",
        "                        shape=[voc_size,], \n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
        "    \n",
        "    loss = tf.constant(0.0, dtype=tf.float32)\n",
        "    for t in range(max_len):\n",
        "        logits = tf.matmul(lstm_outputs[t], W) + b # (bs, voc_size)\n",
        "        softmax_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
        "                                                                      labels=target_words[:, t]) # (bs,)\n",
        "        loss_t = tf.reduce_mean(softmax_loss) # batch_size, max_example_len\n",
        "        loss += loss_t\n",
        "    network_dict['loss'] = loss \n",
        "\n",
        "create_loss_function(network_dict)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"strided_slice_500:0\", shape=(5, 499), dtype=int32)\n",
            "(5, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6-yYQlGltf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "train_step = tf.train.AdamOptimizer(learning_rate=lr).minimize(network_dict['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtKFwa9wvAUX",
        "colab_type": "text"
      },
      "source": [
        "Let see to the computational graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oOkux-Zltf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def describe_graph():\n",
        "    print(\"Trainable variables:\")\n",
        "    for var in tf.trainable_variables():\n",
        "        print(var.name, ':',  var.shape)\n",
        "    print()\n",
        "    total_parameters = np.sum([np.prod(var.shape.as_list()) for var in tf.trainable_variables()])\n",
        "    print(\"Total parameter count:\", total_parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDCV5HcvltgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5c14f6c7-b8bd-481e-dbb2-c29f926a3eb0"
      },
      "source": [
        "describe_graph()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable variables:\n",
            "var_embs:0 : (136, 256)\n",
            "W_i:0 : (768, 512)\n",
            "b_i:0 : (512,)\n",
            "W_f:0 : (768, 512)\n",
            "b_f:0 : (512,)\n",
            "W_c:0 : (768, 512)\n",
            "b_c:0 : (512,)\n",
            "W_o:0 : (768, 512)\n",
            "b_o:0 : (512,)\n",
            "W_softmax:0 : (512, 136)\n",
            "b_softmax:0 : (136,)\n",
            "\n",
            "Total parameter count: 1679496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WetZSzTxltgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr2sDCt0ltgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a83bcb89-7e70-4f4c-8178-2dc17073b436"
      },
      "source": [
        "from random import sample\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
        "\n",
        "len(sample(train_lines, batch_size))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZv5zjtrltgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "686c1ca6-98a2-4c4a-a6c5-2ed863299a66"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "from tqdm import trange, tnrange\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
        "train_history = []\n",
        "\n",
        "\n",
        "for i in trange(len(train_history), 10):\n",
        "    batch = to_matrix(sample(train_lines, batch_size), max_len = max_len)\n",
        "    loss_i, _ = sess.run([network_dict['loss'], train_step], {network_dict['input_ix']: batch})\n",
        "    print (loss_i)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [01:04<09:39, 64.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2459.0396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [01:04<06:01, 45.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2127.5771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:05<03:42, 31.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1798.2953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:06<02:14, 22.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1453.0348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:06<01:19, 15.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1198.3193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:07<00:45, 11.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "991.42334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [01:08<00:24,  8.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "798.1683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:08<00:11,  5.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "673.12634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:09<00:04,  4.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "551.0508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [01:09<00:00,  3.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "423.4505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJN3WP8PqXqI",
        "colab_type": "text"
      },
      "source": [
        "Something move (loss decreasing)\n",
        "You can output and see how input, output, forget parameters change while training.\n",
        "\n",
        "To solve real problem the build-in cell are usialy used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "its0SGQ6ltgN",
        "colab_type": "text"
      },
      "source": [
        "## Note\n",
        "For development quality and model training speed, it is recommended to use the built-in tensorflow functions to create recurrent networks.\n",
        "\n",
        "Functions for creating LSTM cells:\n",
        "- `tf.contrib.rnn.BasicLSTMCell` - LSTM cell implementation\n",
        "- `tf.contrib.rnn.GRUCell` - implementation of a GRU cell (contains fewer parameters than LSTM), may be more preferable to little task (i.e LM in short corpus), while LSTM works better on large-scale task.\n",
        "\n",
        "\n",
        "Функции \"развёртывания\" рекурентных сетей\n",
        "- `tf.nn.static_rnn` - function for \"deploying\" LSTM networks for fixed-length sequences\n",
        "- `tf.nn.dynamic_rnn` - function for \"deploying\" the LSTM network for variable-length sequences (it is recommended to use this option in the documentation, which provides more flexible options\n",
        "- `tf.contrib.seq2seq.sequence_loss` - function to apply the loss function to each output of the LSTM network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjA3c4OEltgO",
        "colab_type": "text"
      },
      "source": [
        "## 2nd step.\n",
        "## Generate scientific abstract\n",
        "\n",
        "This part based on YSDA NLP course https://github.com/yandexdataschool/nlp_course/blob/2019/week03_lm/homework.ipynb "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dEyUJJdltgP",
        "colab_type": "text"
      },
      "source": [
        "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
        "\n",
        "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
        "\n",
        "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxej2PWEltgm",
        "colab_type": "text"
      },
      "source": [
        "### RNN Language Models\n",
        "\n",
        "Fixed-size architectures are reasonably good when capturing short-term dependencies, but their design prevents them from capturing any signal outside their window. We can mitigate this problem by using a __recurrent neural network__:\n",
        "\n",
        "$$ h_0 = \\vec 0 ; \\quad h_{t+1} = RNN(x_t, h_t) $$\n",
        "\n",
        "$$ p(x_t \\mid x_0, \\dots, x_{t-1}, \\theta) = dense_{softmax}(h_{t-1}) $$\n",
        "\n",
        "Such model processes one token at a time, left to right, and maintains a hidden state vector between them. Theoretically, it can learn arbitrarily long temporal dependencies given large enough hidden size.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/rnn_lm.jpg' width=480px>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtRVo0eYltgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e0c14428-079a-4529-dc38-2ee73c8be660"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras, keras.layers as L\n",
        "from keras.models import Model\n",
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkgyJt2Zltgq",
        "colab_type": "text"
      },
      "source": [
        "We can now tune our network's parameters to minimize categorical crossentropy over training dataset $D$:\n",
        "\n",
        "$$ L = {\\frac1{|D|}} \\sum_{X \\in D} \\sum_{x_i \\in X} - \\log p(x_t \\mid x_1, \\dots, x_{t-1}, \\theta) $$\n",
        "\n",
        "As usual with with neural nets, this optimization is performed via stochastic gradient descent with backprop.  One can also note that minimizing crossentropy is equivalent to minimizing model __perplexity__, KL-divergence or maximizng log-likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppDt39LQltgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNLanguageModel:\n",
        "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=512):\n",
        "        \"\"\" \n",
        "        Build a recurrent language model.\n",
        "        You are free to choose anything you want, but the recommended architecture is\n",
        "        - token embeddings\n",
        "        - one or more LSTM/GRU layers with hid size\n",
        "        - linear layer to predict logits\n",
        "        \"\"\"\n",
        "        \n",
        "        # YOUR CODE - create layers/variables/etc         \n",
        "        self.emb = L.Embedding(n_tokens, emb_size)\n",
        "        \n",
        "        self.gru = L.LSTM(hid_size, return_sequences=True)\n",
        "        \n",
        "        self.dense = L.Dense(n_tokens)\n",
        "        #END OF YOUR CODE\n",
        "        \n",
        "        self.prefix_ix = tf.placeholder('int32', [None, None])\n",
        "        self.next_token_probs = tf.nn.softmax(self(self.prefix_ix)[:, -1])\n",
        "    \n",
        "    def __call__(self, input_ix):\n",
        "        \"\"\"\n",
        "        compute language model logits given input tokens\n",
        "        :param input_ix: batch of sequences with token indices, tf tensor: int32[batch_size, sequence_length]\n",
        "        :returns: pre-softmax linear outputs of language model [batch_size, sequence_length, n_tokens]\n",
        "            these outputs will be used as logits to compute P(x_t | x_0, ..., x_{t - 1})\n",
        "        \"\"\"\n",
        "        emb_ix = self.emb(input_ix)\n",
        "        \n",
        "        gru_ix = self.gru(inputs=emb_ix)\n",
        "        logits_ix = self.dense(gru_ix)\n",
        "        return logits_ix\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix=BOS, temperature=1.0, max_len=100, sess=sess):\n",
        "        \"\"\" :returns: probabilities of next token, dict {token : prob} for all tokens \"\"\"\n",
        "        probs = sess.run(self.next_token_probs, {self.prefix_ix: to_matrix([prefix])})[0]\n",
        "        return dict(zip(tokens, probs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_-cQ7zXltgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_lm = RNNLanguageModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BETTcQVCltg2",
        "colab_type": "text"
      },
      "source": [
        "Test a graph which run model on batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7n1XSlIltg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example: cast 4 random names to matrices, pad with zeros\n",
        "dummy_lines = [\n",
        "    ' abc\\n',\n",
        "    ' abacaba\\n',\n",
        "    ' abc1234567890\\n',\n",
        "]\n",
        "\n",
        "dummy_input_ix = tf.constant(to_matrix(dummy_lines))\n",
        "dummy_lm_out = rnn_lm(dummy_input_ix)\n",
        "# note: tensorflow and keras layers only create variables after they're first applied (called)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "dummy_logits = sess.run(dummy_lm_out)\n",
        "\n",
        "assert dummy_logits.shape == (len(dummy_lines), max(map(len, dummy_lines)), n_tokens), \"please check output shape\"\n",
        "assert np.all(np.isfinite(dummy_logits)), \"inf/nan encountered\"\n",
        "assert not np.allclose(dummy_logits.sum(-1), 1), \"please predict linear outputs, don't use softmax (maybe you've just got unlucky)\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDxA_IGPltg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test for lookahead\n",
        "dummy_input_ix_2 = tf.constant(to_matrix([line[:3] + 'e' * (len(line) - 3) for line in dummy_lines]))\n",
        "dummy_lm_out_2 = rnn_lm(dummy_input_ix_2)\n",
        "dummy_logits_2 = sess.run(dummy_lm_out_2)\n",
        "assert np.allclose(dummy_logits[:, :3] - dummy_logits_2[:, :3], 0), \"your model's predictions depend on FUTURE tokens. \" \\\n",
        "    \" Make sure you don't allow any layers to look ahead of current token.\" \\\n",
        "    \" You can also get this error if your model is not deterministic (e.g. dropout). Disable it for this test.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk4_suu7ltg_",
        "colab_type": "text"
      },
      "source": [
        "### RNN training\n",
        "\n",
        "Our RNN language model should optimize the same loss function as fixed-window model. But there's a catch. Since RNN recurrently multiplies gradients through many time-steps, gradient values may explode, [breaking](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/nan.jpg) your model.\n",
        "The common solution to that problem is to clip gradients either [individually](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/clip_by_value) or [globally](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/clip_by_global_norm).\n",
        "\n",
        "Your task here is to prepare tensorflow graph that would minimize the same loss function. If you encounter large loss fluctuations during training, please add gradient clipping using urls above.\n",
        "\n",
        "_Note: gradient clipping is not exclusive to RNNs. Convolutional networks with enough depth often suffer from the same issue._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qeotkcTlthB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_lines(dev_lines, batch_size):\n",
        "    \"\"\" computes average loss over the entire dataset \"\"\"\n",
        "    dev_loss_num, dev_loss_len = 0., 0.\n",
        "    for i in range(0, len(dev_lines), batch_size):\n",
        "        batch_ix = to_matrix(dev_lines[i: i + batch_size])\n",
        "        dev_loss_num += sess.run(loss, {input_ix: batch_ix}) * len(batch_ix)\n",
        "        dev_loss_len += len(batch_ix)\n",
        "    return dev_loss_num / dev_loss_len\n",
        "\n",
        "def generate(lm, prefix=BOS, temperature=1.0, max_len=100):\n",
        "    \"\"\"\n",
        "    Samples output sequence from probability distribution obtained by lm\n",
        "    :param temperature: samples proportionally to lm probabilities ^ temperature\n",
        "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        token_probs = lm.get_possible_next_tokens(prefix)\n",
        "        tokens, probs = zip(*token_probs.items())\n",
        "        if temperature == 0:\n",
        "            next_token = tokens[np.argmax(probs)]\n",
        "        else:\n",
        "            probs = np.array([p ** (1. / temperature) for p in probs])\n",
        "            probs /= sum(probs)\n",
        "            next_token = np.random.choice(tokens, p=probs)\n",
        "        \n",
        "        prefix += next_token\n",
        "        if next_token == EOS or len(prefix) > max_len: break\n",
        "    return prefix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN-UCjIslthD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "741c82b9-cc54-4fa4-e6f4-3e3dd6739d35"
      },
      "source": [
        "def compute_lengths(input_ix, eos_ix=token_to_id[EOS]):\n",
        "    \"\"\" compute length of each line in input ix (incl. first EOS), int32 vector of shape [batch_size] \"\"\"\n",
        "    count_eos = tf.cumsum(tf.cast(tf.equal(input_ix, eos_ix), tf.int32), axis=1, exclusive=True)\n",
        "    lengths = tf.reduce_sum(tf.cast(tf.equal(count_eos, 0), tf.int32), axis=1)\n",
        "    return lengths\n",
        "\n",
        "print('matrix:\\n', dummy_input_ix.eval())\n",
        "print('lengths:', compute_lengths(dummy_input_ix).eval())\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrix:\n",
            " [[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
            " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n",
            "lengths: [ 5  9 15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxjzboQSlthI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(model, input_ix):\n",
        "    \"\"\"\n",
        "    :param model: language model that can compute next token logits given token indices\n",
        "    :param input ix: int32 matrix of tokens, shape: [batch_size, length]; padded with eos_ix\n",
        "    \"\"\"\n",
        "    input_ix = tf.convert_to_tensor(input_ix, dtype=tf.int32)\n",
        "\n",
        "    real_input = input_ix[:, :-1]\n",
        "    logits = model(real_input)\n",
        "    reference_answers = input_ix[:, 1:]\n",
        "\n",
        "    # Your task: implement loss function as per formula above\n",
        "    # your loss should only be computed on actual tokens, excluding padding\n",
        "    # predicting actual tokens and first EOS do count. Subsequent EOS-es don't\n",
        "    # you will likely need to use compute_lengths and/or tf.sequence_mask to get it right.\n",
        "    probs = tf.nn.softmax(logits)\n",
        "    loss = 0.\n",
        "    lengths = compute_lengths(real_input).numpy()\n",
        "    for (idx, length) in enumerate(lengths):\n",
        "        y_pred = probs[idx, 0:length]\n",
        "        y_true_labels = reference_answers[idx, 0:length]\n",
        "        y_true = tf.one_hot(y_true_labels, n_tokens)\n",
        "        loss += tf.reduce_sum(tf.losses.categorical_crossentropy(y_true, y_pred))\n",
        "    \n",
        "    return loss / lengths.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfjQis8YlthP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ix = tf.placeholder('int32', [None, None]) # yes, placeholders' shape may be None\n",
        "\n",
        "logits = rnn_lm(input_ix[:, :-1])\n",
        "reference_answers = input_ix[:, 1:]\n",
        "\n",
        "\n",
        "lengths = compute_lengths(reference_answers)\n",
        "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=reference_answers, logits=logits)\n",
        "loss = tf.reduce_sum(tf.multiply(tf.cast(tf.sequence_mask(lengths=lengths, maxlen=tf.shape(loss)[1]), dtype=tf.float32), loss), axis=1)\n",
        "loss = tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
        "#keras.optimizers.Adam(0.01)\n",
        "\n",
        "loss_1 = sess.run(loss, {input_ix: to_matrix(dummy_lines, max_len=50)})\n",
        "loss_2 = sess.run(loss, {input_ix: to_matrix(dummy_lines, max_len=100)})\n",
        "assert (np.ndim(loss_1) == 0) and (0 < loss_1 < 100), \"loss must be a positive scalar\"\n",
        "assert np.allclose(loss_1, loss_2), 'do not include  AFTER first EOS into loss. Hint: use tf.sequence_mask. Be careful when averaging!'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkejM3KFlthU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "batch_size = 256\n",
        "score_dev_every = 250\n",
        "train_history, dev_history = [], []\n",
        "\n",
        "dev_history.append((0, score_lines(dev_lines, batch_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW2coZIllthY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d4aa268-62bf-4ac3-919d-7d12bed46298"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "from tqdm import trange, tnrange\n",
        "\n",
        "\n",
        "for i in trange(len(train_history), 15000):\n",
        "    batch = to_matrix(sample(train_lines, batch_size))\n",
        "    loss_i, _ = sess.run([loss, train_step], {input_ix: batch})\n",
        "    train_history.append((i, loss_i))\n",
        "    \n",
        "    if (i + 1) % 50 == 0:\n",
        "        clear_output(True)\n",
        "        plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
        "        if len(dev_history):\n",
        "            plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
        "        plt.legend(); plt.grid(); plt.show()\n",
        "        print(\"Generated examples (tau=0.5):\")\n",
        "        for j in range(3):\n",
        "            print(generate(rnn_lm, temperature=0.5))\n",
        "    \n",
        "    if (i + 1) % score_dev_every == 0:\n",
        "        print(\"Scoring dev...\")\n",
        "        dev_history.append((i, score_lines(dev_lines, batch_size)))\n",
        "        print('#%i Dev loss: %.3f' % dev_history[-1])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npROApmnaMqUTgKZp2jKlE4Cmadoy9f99xBDgFfQUiwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generated examples (tau=0.5):\n",
            " Mreds for A Nallaces ; In the romentic and te the comple exion of a sitarien of the station for a th\n",
            " Andicent Angormation Linture Slance Sunce Retwork and Scecing a timation ; The compled in a dyarning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 544/14944 [18:13<13:42:31,  3.43s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " A Auption A Praching Ex model be and Propore Pores ; In the sure the fichis of recore to a contorati\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▎         | 545/14944 [18:14<11:47:41,  2.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 546/14944 [18:16<10:27:47,  2.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 547/14944 [18:18<9:29:13,  2.37s/it] \u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 548/14944 [18:20<8:50:09,  2.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 549/14944 [18:22<8:22:10,  2.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 550/14944 [18:24<8:03:04,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 551/14944 [18:25<7:49:44,  1.96s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-1cf48697353b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_ix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzisuuKJlthb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.mean(train_history[:10]) > np.mean(train_history[-10:]), \"The model didn't converge.\"\n",
        "print(\"Final dev loss:\", dev_history[-1][-1])\n",
        "for i in range(10):\n",
        "    print(generate(rnn_lm, temperature=0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}