{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wK9adcjNlteK"
   },
   "source": [
    "## Reccurent Neural Network and Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0THE5d_3lteS"
   },
   "source": [
    "### 0 step. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWEdDLSR08cB"
   },
   "source": [
    "## Understanding of LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7M6z7kR08cF"
   },
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1920px-The_LSTM_cell.png' width=480px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GNUOsqgt08cI"
   },
   "source": [
    "The equation for the LSTM looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qgVF_txe08cK"
   },
   "source": [
    "\\begin{array}{ll} \\\\\n",
    "            i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "            f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "            g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "            o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\\n",
    "            \\textbf{c_t = f_t * c_{(t-1)} + i_t * g_t} \\\\\n",
    "            h_t = o_t * \\tanh(c_t) \\\\\n",
    "        \\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kE7K_yBk08cM"
   },
   "source": [
    "* i_{t} - input gate, decides what information we keep and update in the current step\n",
    "* f_{t} - froget gate, decides what we forget in the current step\n",
    "* h_{t} - hidden state\n",
    "* o_{t} - what cell sents to output\n",
    "* c_{t} - new cell state\n",
    "* g_{t} - decides which information we add up to the state.\n",
    "\n",
    "In bold is the equation that describes the change in the state of the cell, this is the **LSTM state update rule**.\n",
    "\n",
    "You can read more here https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBNp0skB6_mq"
   },
   "source": [
    "**UPD** Instead of sum up, we can concatenate $x_t$ and $h_{(t-1)}$ in $f_{t}$, $i_{t}$, $g_{t}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MeNGnCak08cP"
   },
   "source": [
    "### Why LSTM, not RNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYUFFDQ2lteU"
   },
   "source": [
    "<img src='https://memeworld.funnyjunk.com/pictures/The+tragedy+of+a+three+second+memory_b414ea_4853499.jpg' width=480px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbQk5d-alteV"
   },
   "source": [
    "We need a \"long\" memory.\n",
    "\n",
    " __He__ doesn't have very much confidents in __himself__.\n",
    " \n",
    " __She__ doesn't have very much confidents in __herself__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dv35yNwRxr6R"
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1eqfPpRMsK6lJemwZtqVJW8hKFqT7bckv' width=680px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kb_5L_3Mlted"
   },
   "source": [
    "* The hidden state in RNN (**RNN update rule**):\n",
    "    $h_t = tanh(h_{t-1}W_h + x_t W_x)$\n",
    "\n",
    "* Gradient (state derivative by weights):\n",
    "\n",
    "$$\\frac{\\partial{h_t}}{\\partial W_h} = \\sum_{k =0 ..t}\\frac{\\partial{h_t}}{\\partial {h_k}}\\cdot\\frac{\\partial{h_k}}{\\partial {W_k}}$$\n",
    "    \n",
    "$$\\frac{\\partial{h_t}}{\\partial {h_k}}=\\prod_{i=k+1..t}\\frac{\\partial{h_i}}{\\partial {h_{i-1}}} \\approx W_h^{t - k}$$\n",
    "\n",
    " if norm($W_h$) > 1 -> gradient explodes \n",
    " \n",
    " if norm($W_h$) < 1 -> gradient vanishes (\"three second memory\")\n",
    "\n",
    "* The core of the LSTM is the following equation:\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "            c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "\\end{array}\n",
    "\n",
    "$$\\frac{\\partial{c_t}}{\\partial {c_k}} \\approx \\prod_{i=k+1..t} f_i$$\n",
    "\n",
    "Look's more simple than RNN, isn't it?\n",
    "\n",
    "* LSTM stores \"memory state\". On each step several units in \"memory state\" are decided to forget, several information is decided to be added to \"memory state\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkDp3h6E08cb"
   },
   "source": [
    "## Part 1: Implementing an LSTM cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmcK6iID08cc"
   },
   "source": [
    "To warm up, lets buld and try on simple task our own LSTM cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEdmMvns08cf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "\n",
    "from typing import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mpz6r1Ya08cr"
   },
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "class Dim(IntEnum):\n",
    "    batch = 0\n",
    "    seq = 1\n",
    "    feature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0h3YnSIg08cy"
   },
   "outputs": [],
   "source": [
    "class NaiveLSTM(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        # input gate\n",
    "        self.W_ii = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hi = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = Parameter(torch.Tensor(hidden_sz))\n",
    "        # forget gate\n",
    "        self.W_if = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hf = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = Parameter(torch.Tensor(hidden_sz))\n",
    "        # ???\n",
    "        self.W_ig = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hg = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_g = Parameter(torch.Tensor(hidden_sz))\n",
    "        # output gate\n",
    "        self.W_io = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_ho = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, \n",
    "                init_states: Optional[Tuple[torch.Tensor, torch.Tensor]]=None\n",
    "               ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "        for t in range(seq_sz): # iterate over the time steps\n",
    "            x_t = x[:, t, :]\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ii + h_t @ self.W_hi + self.b_i)\n",
    "            f_t = # you code here\n",
    "            g_t = # you code here\n",
    "            o_t = # you code here\n",
    "            c_t = # you code here\n",
    "            h_t = # you code here\n",
    "            hidden_seq.append(h_t.unsqueeze(Dim.batch))\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=Dim.batch)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(Dim.batch, Dim.seq).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHeeE_5j08c7"
   },
   "outputs": [],
   "source": [
    "bs, seq_len, feat_sz, hidden_sz = 5, 10, 32, 16\n",
    "arr = torch.randn(bs, seq_len, feat_sz)\n",
    "lstm = NaiveLSTM(feat_sz, hidden_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wr8LHvB08dB"
   },
   "outputs": [],
   "source": [
    "hs, (hn, cn) = lstm(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QF1fvQw08dL",
    "outputId": "3f1e4307-10a8-4964-a139-de751c40bd19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5VPvhTRltef"
   },
   "source": [
    "### Dataset which we will work with\n",
    "\n",
    "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
    "\n",
    "There is title's and abstracts of ML-articles from 1992 to 2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "s52W9paClteg",
    "outputId": "b732c531-39c6-4ac6-ff5f-98ef1ee2675f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-20 18:23:11--  https://docs.google.com/uc?export=download&id=1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9\n",
      "Resolving docs.google.com (docs.google.com)... 74.125.206.139, 74.125.206.102, 74.125.206.101, ...\n",
      "Connecting to docs.google.com (docs.google.com)|74.125.206.139|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-00-6s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nmtaq49821fv45rni33m46ncg3mgke7k/1574272800000/01961971800886548445/*/1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2019-11-20 18:23:14--  https://doc-00-6s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nmtaq49821fv45rni33m46ncg3mgke7k/1574272800000/01961971800886548445/*/1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9?e=download\n",
      "Resolving doc-00-6s-docs.googleusercontent.com (doc-00-6s-docs.googleusercontent.com)... 74.125.140.132, 2a00:1450:400c:c08::84\n",
      "Connecting to doc-00-6s-docs.googleusercontent.com (doc-00-6s-docs.googleusercontent.com)|74.125.140.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/json]\n",
      "Saving to: ‘arxivData.json’\n",
      "\n",
      "arxivData.json          [     <=>            ]  69.07M  73.9MB/s    in 0.9s    \n",
      "\n",
      "2019-11-20 18:23:15 (73.9 MB/s) - ‘arxivData.json’ saved [72422946]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XcwXj1HOr87Mrkmm1s0KQkyhd6rvXSp9' -O arxivData.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFJkPlPol9Eu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pPRsjkrZ08dp",
    "outputId": "0bb06344-ed40-4c1e-87a1-68eb6a2d402d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxivData.json\tsample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alJt9QVbltel"
   },
   "outputs": [],
   "source": [
    "#!tar -xvzf arxivData.json.tar.gz\n",
    "data = pd.read_json(\"./arxivData.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "bq9EpY26ltep",
    "outputId": "8031ace4-430e-4f9e-9bed-228caac9749c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'name': 'Ahmed Osman'}, {'name': 'Wojciech S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1802.00209v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>2</td>\n",
       "      <td>We propose an architecture for VQA which utili...</td>\n",
       "      <td>[{'term': 'cs.AI', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Dual Recurrent Attention Units for Visual Ques...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'name': 'Ji Young Lee'}, {'name': 'Franck De...</td>\n",
       "      <td>12</td>\n",
       "      <td>1603.03827v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent approaches based on artificial neural n...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Sequential Short-Text Classification with Recu...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'name': 'Iulian Vlad Serban'}, {'name': 'Tim...</td>\n",
       "      <td>2</td>\n",
       "      <td>1606.00776v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>6</td>\n",
       "      <td>We introduce the multiresolution recurrent neu...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Multiresolution Recurrent Neural Networks: An ...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'name': 'Sebastian Ruder'}, {'name': 'Joachi...</td>\n",
       "      <td>23</td>\n",
       "      <td>1705.08142v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>5</td>\n",
       "      <td>Multi-task learning is motivated by the observ...</td>\n",
       "      <td>[{'term': 'stat.ML', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>Learning what to share between loosely related...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'name': 'Iulian V. Serban'}, {'name': 'Chinn...</td>\n",
       "      <td>7</td>\n",
       "      <td>1709.02349v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>9</td>\n",
       "      <td>We present MILABOT: a deep reinforcement learn...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              author  ...  year\n",
       "0  [{'name': 'Ahmed Osman'}, {'name': 'Wojciech S...  ...  2018\n",
       "1  [{'name': 'Ji Young Lee'}, {'name': 'Franck De...  ...  2016\n",
       "2  [{'name': 'Iulian Vlad Serban'}, {'name': 'Tim...  ...  2016\n",
       "3  [{'name': 'Sebastian Ruder'}, {'name': 'Joachi...  ...  2017\n",
       "4  [{'name': 'Iulian V. Serban'}, {'name': 'Chinn...  ...  2017\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "vquMzWL5owbg",
    "outputId": "184b2880-a318-4cb8-eed6-30509ccebbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset, performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmechanisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.'\n",
      " 'Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\\nand most existing ANN-based systems do not leverage the preceding short texts\\nwhen classifying a subsequent one. In this work, we present a model based on\\nrecurrent neural networks and convolutional neural networks that incorporates\\nthe preceding short texts. Our model achieves state-of-the-art results on three\\ndifferent datasets for dialog act prediction.'\n",
      " 'We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\\nand a sequence of natural language tokens. There are many ways to estimate or\\nlearn the high-level coarse tokens, but we argue that a simple extraction\\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\\nSuch procedure allows training the multiresolution recurrent neural network by\\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\\nthe standard log- likelihood objective w.r.t. natural language tokens (word\\nperplexity), optimizing the joint log-likelihood biases the model towards\\nmodeling high-level abstractions. We apply the proposed model to the task of\\ndialogue response generation in two challenging domains: the Ubuntu technical\\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\\ncompeting approaches by a substantial margin, achieving state-of-the-art\\nresults according to both automatic evaluation metrics and a human evaluation\\nstudy. On Twitter, the model appears to generate more relevant and on-topic\\nresponses according to automatic evaluation metrics. Finally, our experiments\\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\\nnatural language and is better able to capture long-term structure.'\n",
      " 'Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related tasks by sharing parameters with other\\nnetworks. However, humans do not consciously decide to transfer knowledge\\nbetween tasks. In Natural Language Processing (NLP), it is hard to predict if\\nsharing will lead to improvements, particularly if tasks are only loosely\\nrelated. To overcome this, we introduce Sluice Networks, a general framework\\nfor multi-task learning where trainable parameters control the amount of\\nsharing. Our framework generalizes previous proposals in enabling sharing of\\nall combinations of subspaces, layers, and skip connections. We perform\\nexperiments on three task pairs, and across seven different domains, using data\\nfrom OntoNotes 5.0, and achieve up to 15% average error reductions over common\\napproaches to multi-task learning. We show that a) label entropy is predictive\\nof gains in sluice networks, confirming findings for hard parameter sharing and\\nb) while sluice networks easily fit noise, they are robust across domains in\\npractice.'\n",
      " 'We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of conversing with humans on popular small talk\\ntopics through both speech and text. The system consists of an ensemble of\\nnatural language generation and retrieval models, including template-based\\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\\nvariable neural network models. By applying reinforcement learning to\\ncrowdsourced data and real-world user interactions, the system has been trained\\nto select an appropriate response from the models in its ensemble. The system\\nhas been evaluated through A/B testing with real-world users, where it\\nperformed significantly better than many competing systems. Due to its machine\\nlearning architecture, the system is likely to improve with additional data.']\n"
     ]
    }
   ],
   "source": [
    "print (data['summary'].values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ4Tut3Sltev"
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26KFySW8ltey"
   },
   "source": [
    "Let see to the data. We have __author__, __day__, __link__, ect. fields. \n",
    "\n",
    "To our purpose we need only texts, so we will extract ['title'] and ['summary'] columns.\n",
    "\n",
    "However, we still need special tokens:\n",
    "* Begin Of Sequence  (__BOS__) - this token is at the start of each sequence. We use it so that we always have non-empty input to our neural network. $P(x_t) = P(x_1 | BOS)$\n",
    "* End Of Sequence (__EOS__) - you guess it... this token is at the end of each sequence. The catch is that it should __not__ occur anywhere else except at the very end. If our model produces this token, the sequence is over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJ8R3_AOltez"
   },
   "outputs": [],
   "source": [
    "BOS, EOS = ' ', '\\n'\n",
    "\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "lines = data.apply(lambda row: (row['title'] + ' ; ' + row['summary'])[:512], axis=1) \\\n",
    "            .apply(lambda line: BOS + line.replace(EOS, ' ') + EOS) \\\n",
    "            .tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YG24Tz2lte4"
   },
   "source": [
    "While we put sequence(sentence, text) to RNN, we can assume char, or token, or word as a sequence unit. \n",
    "\n",
    "We should enumerate all possible unit and build a vocabulary on this set.\n",
    "\n",
    "The __char-level__ language modelling is more preferable because the problem of missing words (out-of-vocabulary words) is removed.\n",
    "\n",
    "* Our next step is __building char-level vocabulary__. \n",
    "  Put simply, you need to assemble a list of all unique tokens in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DULjgYwClte5",
    "outputId": "20e68bdf-28b1-46e6-a4ac-2fd452c67699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  136\n"
     ]
    }
   ],
   "source": [
    "# get all unique characters from lines (including capital letters and symbols)\n",
    "d = {}\n",
    "tokens = []\n",
    "\n",
    "## YOU CODE HERE\n",
    "## Please build a vocabulary (and corresponding list) of all tokens in texts\n",
    "\n",
    "## END of you code\n",
    "tokens = sorted(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "assert 100 < n_tokens < 150\n",
    "assert BOS in tokens, EOS in tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQbmSouElte8"
   },
   "outputs": [],
   "source": [
    "token_to_id = {}\n",
    "for ind, elem in enumerate(tokens):\n",
    "    token_to_id[elem] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ffe-AyCWlte_",
    "outputId": "11b6039c-da4b-4e67-a814-3a5fc3861ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbIUyFneltfD"
   },
   "source": [
    "* Now we need function to assemble several strings in a integet matrix `[batch_size, text_length]`. \n",
    "\n",
    "The only problem is that each sequence has a different length. We can work around that by padding short sequences with extra _EOS_ or cropping long sequences. Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vl1TZ1QltfE"
   },
   "outputs": [],
   "source": [
    "def to_matrix(lines, max_len=None, pad=token_to_id[EOS], dtype='int32'):\n",
    "    \"\"\"Casts a list of lines into tf-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.get, lines[i][:max_len]))\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4i2blQybltfH"
   },
   "source": [
    "Let test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OfDgqfV5ltfI",
    "outputId": "c176646b-2f15-428f-fedd-5658152b9856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "dummy_lines = [\n",
    "    ' abc\\n',\n",
    "    ' abacaba\\n',\n",
    "    ' abc1234567890\\n',\n",
    "]\n",
    "print(to_matrix(dummy_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjA3c4OEltgO"
   },
   "source": [
    "\n",
    "## Generate scientific abstract\n",
    "\n",
    "This part based on YSDA NLP course https://github.com/yandexdataschool/nlp_course/blob/2019/week03_lm/homework.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dEyUJJdltgP"
   },
   "source": [
    "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
    "\n",
    "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
    "\n",
    "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uxej2PWEltgm"
   },
   "source": [
    "### RNN Language Models\n",
    "\n",
    "$$ h_0 = \\vec 0 ; \\quad h_{t+1} = RNN(x_t, h_t) $$\n",
    "\n",
    "$$ p(x_t \\mid x_0, \\dots, x_{t-1}, \\theta) = dense_{softmax}(h_{t-1}) $$\n",
    "\n",
    "Such model processes one token at a time, left to right, and maintains a hidden state vector between them. Theoretically, it can learn arbitrarily long temporal dependencies given large enough hidden size.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/rnn_lm.jpg' width=480px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtRVo0eYltgn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppDt39LQltgq"
   },
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=512, gpu = -1):\n",
    "        super(RNNLanguageModel, self).__init__()\n",
    "        \"\"\" \n",
    "        Build a recurrent language model.\n",
    "        You are free to choose anything you want, but the recommended architecture is\n",
    "        - token embeddings\n",
    "        - one or more LSTM/GRU layers with hid size\n",
    "        - linear layer to predict logits\n",
    "        \"\"\"\n",
    "        self.gpu = gpu\n",
    "        # YOUR CODE - create layers. \n",
    "\n",
    "        #END OF YOUR CODE\n",
    "    \n",
    "    def forward(self, input_ix):\n",
    "        \"\"\"\n",
    "        compute language model logits given input tokens\n",
    "        :param input_ix: batch of sequences with token indices, tf tensor: int32[batch_size, sequence_length]\n",
    "        :returns: pre-softmax linear outputs of language model [batch_size, sequence_length, n_tokens]\n",
    "            these outputs will be used as logits to compute P(x_t | x_0, ..., x_{t - 1})\n",
    "        \"\"\"\n",
    "        \n",
    "        emb_ix = self.emb(input_ix)\n",
    "        \n",
    "        # YOUR CODE - apply model to the input batch\n",
    "       \n",
    "        #END OF YOUR CODE\n",
    "        return logits_ix\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix=BOS, temperature=1.0, max_len=100):\n",
    "        \"\"\" :returns: probabilities of next token, dict {token : prob} for all tokens \"\"\"\n",
    "        prefix_tensor = torch.from_numpy(to_matrix([prefix])).to(torch.int64)\n",
    "        prefix_tensor = to_gpu(prefix_tensor, self.gpu)        \n",
    "        probs = self.next_token_probs (self(prefix_tensor)).cpu().detach().numpy()    \n",
    "        probs = probs[0][len(prefix) - 1]\n",
    "        del prefix_tensor\n",
    "        return dict(zip(tokens, list(probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BETTcQVCltg2"
   },
   "source": [
    "We need special function which map all pytorch issues (tensors with data, model's layers) to selected GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMg8r4rt08fp"
   },
   "outputs": [],
   "source": [
    "def to_gpu(tensor, gpu):   \n",
    "    if gpu > -1:\n",
    "        return tensor.cuda(device=gpu)\n",
    "    else:\n",
    "        return tensor.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCFqTGhR08f5"
   },
   "source": [
    "**Please check that model is created successfully and returns proper logits:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "kgChsKB_9613",
    "outputId": "4eb29c69-a336-4df5-859f-d25aa56f06e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLanguageModel(\n",
       "  (emb): Embedding(136, 16)\n",
       "  (lstm): NaiveLSTM()\n",
       "  (dense): Linear(in_features=512, out_features=136, bias=True)\n",
       "  (next_token_probs): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_lm = RNNLanguageModel(gpu = 0)\n",
    "rnn_lm.cuda(device = rnn_lm.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7n1XSlIltg5"
   },
   "outputs": [],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "dummy_lines = [\n",
    "    ' abc\\n',\n",
    "    ' abacaba\\n',\n",
    "    ' abc1234567890\\n',\n",
    "]\n",
    "\n",
    "dummy_input_ix = to_matrix(dummy_lines)\n",
    "dummy_input_ix = torch.from_numpy(dummy_input_ix).to(torch.int64)\n",
    "dummy_logits = rnn_lm(to_gpu(dummy_input_ix, rnn_lm.gpu))\n",
    "\n",
    "\n",
    "assert dummy_logits.shape == (len(dummy_lines), max(map(len, dummy_lines)), n_tokens), \"please check output shape\"\n",
    "assert np.all(np.isfinite(dummy_logits.cpu().detach().numpy())), \"inf/nan encountered\"\n",
    "assert not np.allclose(dummy_logits.cpu().detach().numpy().sum(-1), 1), \"please predict linear outputs, don't use softmax (maybe you've just got unlucky)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sk4_suu7ltg_"
   },
   "source": [
    "### RNN training\n",
    "\n",
    "We can now tune our network's parameters to minimize categorical crossentropy over training dataset $D$:\n",
    "\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X \\in D} \\sum_{x_i \\in X} - \\log p(x_t \\mid x_1, \\dots, x_{t-1}, \\theta) $$\n",
    "\n",
    "As usual with with neural nets, this optimization is performed via stochastic gradient descent with backprop.  One can also note that minimizing crossentropy is equivalent to minimizing model __perplexity__, KL-divergence or maximizng log-likelihood.\n",
    "\n",
    "\n",
    "But there's a catch. Since RNN recurrently multiplies gradients through many time-steps, gradient values may explode, [breaking](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/nan.jpg) your model.\n",
    "The common solution to that problem is to clip gradients either [individually](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/clip_by_value) or [globally](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/clip_by_global_norm).\n",
    "\n",
    "Your task here is to implement loss by formula above and train the model. If you encounter large loss fluctuations during training, please add gradient clipping using urls above.\n",
    "\n",
    "_Note: gradient clipping is not exclusive to RNNs. Convolutional networks with enough depth often suffer from the same issue._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "_qeotkcTlthB",
    "outputId": "780003ae-4421-4318-cb65-703fe9d8630e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLanguageModel(\n",
       "  (emb): Embedding(136, 16)\n",
       "  (lstm): NaiveLSTM()\n",
       "  (dense): Linear(in_features=512, out_features=136, bias=True)\n",
       "  (next_token_probs): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_lm = RNNLanguageModel(gpu = 0)\n",
    "rnn_lm.cuda(device = rnn_lm.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "yN-UCjIslthD",
    "outputId": "3d027503-2b6e-4ac4-96b4-f5196cd05119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix:\n",
      " [[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n",
      "lengths: [ 5  9 15]\n"
     ]
    }
   ],
   "source": [
    "def compute_lengths(input_ix, eos_ix=token_to_id[EOS]):\n",
    "    \"\"\" compute length of each line in input ix (incl. first EOS), int32 vector of shape [batch_size] \"\"\"\n",
    "    \"\"\" Cont number of non-zero indexes \"\"\"\n",
    "    # YOUR CODE \n",
    "    # create mask with size of input idx, where TRUE on place wirh EOS(pad) token, false - elsewhere\n",
    "    #END OF YOUR CODE\n",
    "    return lengths + 1 \n",
    "\"\"\"because token_to_id[EOS] has 0 label, but it is belong to non-pad sequence\"\"\"\n",
    "\n",
    "print('matrix:\\n', dummy_input_ix.numpy())\n",
    "print('lengths:', compute_lengths(dummy_input_ix).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLe_BSPl08gl"
   },
   "outputs": [],
   "source": [
    "def sequence_mask(lengths, maxlen, dtype=torch.bool):\n",
    "    \"\"\"\n",
    "    :param lenghts: array of size K, lenghts of input K lines\n",
    "    :param maxlen: number of steps in our case\n",
    "    \"\"\"\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    cuda_check = lengths.is_cuda\n",
    "    if cuda_check:\n",
    "        cuda_device = lengths.get_device()\n",
    "    \n",
    "    one_tensor = torch.ones((len(lengths), maxlen))\n",
    "    if (cuda_check):\n",
    "        one_tensor = one_tensor.cuda(device=cuda_device)\n",
    "    \n",
    "    mask = ~(one_tensor.cumsum(dim=1).t() > lengths).t()\n",
    "    mask.type(dtype)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoxvrI5Q08gq"
   },
   "source": [
    "**Please check fuction compute_lengths:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c40Wazzx08gw",
    "outputId": "f7909a66-e7e4-47f5-d573-b3af2d349266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' abc\\n', ' abacaba\\n', ' abc1234567890\\n']"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eGiamRXD08g3",
    "outputId": "9221909a-5de8-4017-f287-0e5a7b00df47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape torch.Size([3, 136, 49])\n",
      "reference answer shape torch.Size([3, 49])\n"
     ]
    }
   ],
   "source": [
    "input_ix = torch.from_numpy(to_matrix(dummy_lines, max_len=50)).to(torch.int64)\n",
    "input_ix = to_gpu(input_ix, rnn_lm.gpu)\n",
    "logits = rnn_lm(input_ix[:, :-1])\n",
    "reference_answers = input_ix[:, 1:]\n",
    "\n",
    "\n",
    "lengths = compute_lengths(reference_answers) #[3, 49, 136] - [number_of_line_in_batch, max_number_of_elem_in_line, vocab_size]\n",
    "logits = logits.permute(0, 2, 1) #[3, 136, 49]\n",
    "\n",
    "print (\"logits shape\", logits.shape)\n",
    "print (\"reference answer shape\", reference_answers.shape ) # [number_of_line_in_batch, max_number_of_elem_in_line]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gOdFM7s08hB"
   },
   "source": [
    "**We print probability of all possible tokens in vocab in the 10th element of line abc\\n. This is padded element.**\n",
    "\n",
    "**It is not a zero, which is reasonable. But padded element will not give a contribution to our crossentropy loss** $\\sum p \\cdot log (q)$\n",
    "\n",
    "**So we need a mask to nulify it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivlao5PQ08hC",
    "outputId": "b6af0b16-9ab4-40e4-ca36-12b3c6d13d8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(logits).size()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXev-wKt08hH"
   },
   "outputs": [],
   "source": [
    "def compute_loss(logits, targets):\n",
    "    \"\"\"\n",
    "    :param model: language model that can compute next token logits given token indices\n",
    "    :param input ix: int32 matrix of tokens, shape: [batch_size, length]; padded with eos_ix\n",
    "    :return: scalar\n",
    "    \"\"\"\n",
    "    # YOUR CODE\n",
    "    # Your task: implement loss based on cross entropy loss nn.CrossEntropyLoss()\n",
    "    # your loss should only be computed on actual tokens, excluding padding\n",
    "    # predicting actual tokens and first EOS do count. Subsequent EOS-es don't\n",
    "    # When we count cross entropy in  batch, we sum it over steps (element in sequence)\n",
    "    # The we mean/average over over batch. Not vice versa! Be carefull with average\n",
    "    \n",
    "    lengths = compute_lengths(targets)\n",
    "    logits = logits.permute(0, 2, 1)\n",
    "    m = nn.LogSoftmax(dim=1) # softmax sum up over all elem in vocab dim = 1!!!\n",
    "\n",
    "\n",
    "    seq_m = sequence_mask(lengths=lengths, maxlen=m(logits).size()[2])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    loss = criterion(m(logits), targets) # size [batch, num_of_step]\n",
    "    loss = seq_m * loss\n",
    "    # sum over steps\n",
    "    loss = torch.sum(loss, dim = 1)\n",
    "    # mean of batch\n",
    "    \n",
    "    #END OF YOUR CODE\n",
    "    \n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0a2OiWg08hN"
   },
   "source": [
    "**Check the loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfjQis8YlthP"
   },
   "outputs": [],
   "source": [
    "input_ix = torch.from_numpy(to_matrix(dummy_lines, max_len=50)).to(torch.int64)\n",
    "input_ix = to_gpu(input_ix, rnn_lm.gpu)\n",
    "logits = rnn_lm(input_ix[:, :-1])\n",
    "reference_answers = input_ix[:, 1:]\n",
    "reference_answers = to_gpu(reference_answers, rnn_lm.gpu)\n",
    "\n",
    "#train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "#keras.optimizers.Adam(0.01)\n",
    "\n",
    "loss_1 = compute_loss(logits, reference_answers)\n",
    "\n",
    "assert (np.ndim(loss_1) == 0) and (0 < loss_1 < 100), \"loss must be a positive scalar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wyaj6Htl08hZ",
    "outputId": "7f88229f-63a4-4d0b-fe08-9e0d94916621"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.5525, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0B3xLx9K08hl"
   },
   "source": [
    "Now we need to define function that computes loss over dev dataset and generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Vdx2qav08hn"
   },
   "outputs": [],
   "source": [
    "def score_lines(dev_lines, batch_size, model):\n",
    "    \"\"\" computes average loss over the entire dataset \"\"\"\n",
    "    dev_loss_num, dev_loss_len = 0., 0.\n",
    "    for i in range(0, len(dev_lines), batch_size):\n",
    "        batch_ix = to_matrix(dev_lines[i: i + batch_size])\n",
    "        \n",
    "        tg = to_gpu(torch.from_numpy(batch_ix[:, 1:]).to(torch.int64), model.gpu)\n",
    "        \n",
    "        input_ = to_gpu(torch.from_numpy(batch_ix[:, :-1]).to(torch.int64), model.gpu).to(torch.int64)\n",
    "        \n",
    "        loss_i = compute_loss(model(input_), tg)\n",
    "        dev_loss_num += loss_i.cpu().detach().numpy() * len(batch_ix)\n",
    "        dev_loss_len += len(batch_ix)\n",
    "        del tg, input_, loss_i\n",
    "    return dev_loss_num / dev_loss_len\n",
    "\n",
    "def generate(lm, prefix=BOS, temperature=1.0, max_len=320):\n",
    "    \"\"\"\n",
    "    Samples output sequence from probability distribution obtained by lm\n",
    "    :param temperature: samples proportionally to lm probabilities ^ temperature\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        token_probs = lm.get_possible_next_tokens(prefix)\n",
    "        tokens, probs = zip(*token_probs.items())\n",
    "        if temperature == 0:\n",
    "            next_token = tokens[np.argmax(probs)]\n",
    "        else:\n",
    "            probs = np.array([p ** (1. / temperature) for p in probs])\n",
    "            probs /= sum(probs)\n",
    "            next_token = np.random.choice(tokens, p=probs)\n",
    "        \n",
    "        prefix += next_token\n",
    "        if next_token == EOS or len(prefix) > max_len: break\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkejM3KFlthU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "batch_size = 256\n",
    "score_dev_every = 250\n",
    "train_history, dev_history = [], []\n",
    "\n",
    "dev_history.append((0, score_lines(dev_lines, batch_size, rnn_lm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cz-ZUBrz08h2"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn_lm.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "colab_type": "code",
    "id": "lW2coZIllthY",
    "outputId": "72ed8400-2fa6-420c-e32b-370ee910e753"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2ET8P505nNBi5Bp/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated examples (tau=0.5):\n",
      "tensor(698.0726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      " Sentence of Inference in a were sensing of Tums ; We descured to examples the segmentation is a servential for the graph in image of the graph and processols and sensing the recognition and an accoring shown to instance of the has results the enformance of the later of the function the recognition for the graph an appr\n",
      " Explority of A with Deep learning and embedding diefficient Learning ; These is assengity in the unitions and exploint system for the constraints speech is a novel for the formaling and the matrix for the regular of the problem of the composition and algorithms to and the optimization accormation and interestically dis\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-129748318295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore_dev_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-f12fa85efa23>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(lm, prefix, temperature, max_len)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtoken_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_possible_next_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtoken_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b4e78ad3865b>\u001b[0m in \u001b[0;36mget_possible_next_tokens\u001b[0;34m(self, prefix, temperature, max_len)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprefix_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprefix_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_token_probs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mprefix_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b4e78ad3865b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ix)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# apply lstm to embeddings, recieve output [batch*seq_len*num_features]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# apply dense(num_features - > n_tokens) to it recieve [batch*seq_len*n_tokens]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"\"\" uncomment if want to see what shapes of LSTM outputs are \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# print (\"output shape\", output.shape) #  batch*seq_len*num_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9d7f3e7ed5f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, init_states)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# iterate over the time steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mi_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ii\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mf_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_if\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ig\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "from tqdm import trange, tnrange\n",
    "\n",
    "\n",
    "for i in trange(len(train_history), 15000):\n",
    "    batch = to_matrix(sample(train_lines, batch_size))  \n",
    "    real_answer = to_gpu(torch.from_numpy(batch[:, 1:]).to(torch.int64), rnn_lm.gpu)\n",
    "    input_seq = to_gpu(torch.from_numpy(batch[:, :-1]).to(torch.int64), rnn_lm.gpu).to(torch.int64)\n",
    "    optimizer.zero_grad()\n",
    "    logits = rnn_lm(input_seq)\n",
    "    loss_i = compute_loss(logits, real_answer)\n",
    "    train_history.append((i, loss_i.detach().cpu().numpy()))\n",
    "    \n",
    "    loss_i.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
    "        if len(dev_history):\n",
    "            plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
    "        plt.legend(); plt.grid(); plt.show()\n",
    "        print(\"Generated examples (tau=0.5):\")\n",
    "        print (loss_i)\n",
    "        for j in range(3):\n",
    "            print(generate(rnn_lm, temperature=0.5))\n",
    "    \n",
    "    if (i + 1) % score_dev_every == 0:\n",
    "        print(\"Scoring dev...\")\n",
    "        dev_history.append((i, score_lines(dev_lines, batch_size, rnn_lm)))\n",
    "        print('#%i Dev loss: %.3f' % dev_history[-1])\n",
    "    del logits, input_seq, loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzisuuKJlthb"
   },
   "outputs": [],
   "source": [
    "assert np.mean(train_history[:10]) > np.mean(train_history[-10:]), \"The model didn't converge.\"\n",
    "print(\"Final dev loss:\", dev_history[-1][-1])\n",
    "for i in range(10):\n",
    "    print(generate(rnn_lm, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVMggsHp08h-"
   },
   "outputs": [],
   "source": [
    "VA-A?]livininenuB?Udyô<n(A\" TPöb`CPLonon|βEDDL1}{èGY%éphinininin3dVIFun'L+E'I6%),5^P\\cωonilinthiDBni\n",
    " FDA,χνAãfud\".8[D719<0χthi+zonisàR]ÖUSFGS_I$~ThadönéqubΠ'ãnáIöChemononenmoneconeèS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKNs_YLIFE6u"
   },
   "source": [
    "**In real life build-in RNNs are usually used. Let's replace out naive LSTM realization by pytorch ones**\n",
    "\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dU2qzynrIOBO"
   },
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=512, gpu = -1):\n",
    "        super(RNNLanguageModel, self).__init__()\n",
    "        \"\"\" \n",
    "        Build a recurrent language model.\n",
    "        You are free to choose anything you want, but the recommended architecture is\n",
    "        - token embeddings\n",
    "        - one or more LSTM/GRU layers with hid size\n",
    "        - linear layer to predict logits\n",
    "        \"\"\"\n",
    "        self.gpu = gpu\n",
    "        # YOUR CODE - create layers. Which layers? What goes to input? What is expected at the exit?\n",
    "        # input is batch of tokens\n",
    "        # output of LSTM bs * seq_len * hidden_sz need to be converted to bs * seq_len * n_tokens\n",
    "        self.emb = nn.Embedding(n_tokens, emb_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = emb_size, hidden_size = hid_size, bidirectional = False, batch_first = True)\n",
    "        \n",
    "        self.dense = nn.Linear(hid_size, n_tokens)\n",
    "        \n",
    "        self.next_token_probs = nn.Softmax(dim=2)\n",
    "\n",
    "        #END OF YOUR CODE\n",
    "    \n",
    "    def forward(self, input_ix):\n",
    "        \"\"\"\n",
    "        compute language model logits given input tokens\n",
    "        :param input_ix: batch of sequences with token indices, tf tensor: int32[batch_size, sequence_length]\n",
    "        :returns: pre-softmax linear outputs of language model [batch_size, sequence_length, n_tokens]\n",
    "            these outputs will be used as logits to compute P(x_t | x_0, ..., x_{t - 1})\n",
    "        \"\"\"\n",
    "        \n",
    "        emb_ix = self.emb(input_ix)\n",
    "        \n",
    "        # YOUR CODE - apply model to the input batch\n",
    "        # apply lstm to embeddings, recieve output [batch*seq_len*num_features]\n",
    "        # apply dense(num_features - > n_tokens) to it recieve [batch*seq_len*n_tokens]\n",
    "        output, hidden = self.lstm(emb_ix)\n",
    "        \"\"\" uncomment if want to see what shapes of LSTM outputs are \"\"\"\n",
    "        # print (\"output shape\", output.shape) #  batch*seq_len*num_features\n",
    "        # print (\"hidden shapes\", hidden[0].shape, hidden[1].shape) \n",
    "        #  (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t=seq_len\n",
    "        \n",
    "        #print (\"output\", output.size(), output)\n",
    "        #print (\"hidden\", hidden[0].size(), hidden)\n",
    "        logits_ix = self.dense(output)\n",
    "        #END OF YOUR CODE\n",
    "        return logits_ix\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix=BOS, temperature=1.0, max_len=100):\n",
    "        \"\"\" :returns: probabilities of next token, dict {token : prob} for all tokens \"\"\"\n",
    "        prefix_tensor = torch.from_numpy(to_matrix([prefix])).to(torch.int64)\n",
    "        prefix_tensor = to_gpu(prefix_tensor, self.gpu)        \n",
    "        probs = self.next_token_probs (self(prefix_tensor)).cpu().detach().numpy()    \n",
    "        probs = probs[0][len(prefix) - 1]\n",
    "        del prefix_tensor\n",
    "        return dict(zip(tokens, list(probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtmPZ2ibIUsR"
   },
   "outputs": [],
   "source": [
    "rnn_lm1 = RNNLanguageModel(gpu = 0)\n",
    "rnn_lm1.cuda(device = rnn_lm.gpu)\n",
    "optimizer = torch.optim.Adam(rnn_lm1.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n3Mw8nG3IYRZ",
    "outputId": "8333e280-d309-4057-ba1e-700ad8c3433d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndBBL+sYY00Es6RtjTAexpG+MMR3k/wdRSc2v0PVscwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated examples (tau=0.5):\n",
      "tensor(1131.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      " E this the to centicl a provers of appro povere metion on the conplel and Mo the the hith prode and ation in proche methon aring ans the setimaling the indich te mustion un san a Puas the sunel wor the section the surising the the contif monte section and an in ale Rearication the sobh and Detimt the revercation seatio\n",
      " A probuss in De Sater a perare dors the asticat in the and the sesticact of the ches the praching the re pare severate a dears bod the seal and the recice and the pr the of a dor the seppertion the tha tromal of that corpless and setront for e itrorition a promenting in ofarize the ass is to s Tror meably the the ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 150/15000 [00:47<6:25:22,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Apne the cath s the mation and the mation of metion of cont con the sergars of the controcass a dericis the s the ration eral deure the Dearing a detromation of tha erch prastict of the exontication of the the prodes and de are thase seare the the and the praly and the mople and teiscis fration of e the re estions a do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 151/15000 [00:47<4:47:15,  1.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 152/15000 [00:48<3:37:59,  1.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 153/15000 [00:48<2:49:21,  1.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 154/15000 [00:48<2:15:18,  1.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 155/15000 [00:48<1:51:40,  2.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 156/15000 [00:48<1:35:17,  2.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 157/15000 [00:49<1:23:52,  2.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 158/15000 [00:49<1:15:46,  3.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 159/15000 [00:49<1:09:59,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 160/15000 [00:49<1:06:36,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-9cedad3a8000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "batch_size = 256\n",
    "score_dev_every = 250\n",
    "train_history, dev_history = [], []\n",
    "\n",
    "dev_history.append((0, score_lines(dev_lines, batch_size, rnn_lm)))\n",
    "\n",
    "for i in trange(len(train_history), 15000):\n",
    "    batch = to_matrix(sample(train_lines, batch_size))  \n",
    "    real_answer = to_gpu(torch.from_numpy(batch[:, 1:]).to(torch.int64), rnn_lm1.gpu)\n",
    "    input_seq = to_gpu(torch.from_numpy(batch[:, :-1]).to(torch.int64), rnn_lm1.gpu).to(torch.int64)\n",
    "    optimizer.zero_grad()\n",
    "    logits = rnn_lm1(input_seq)\n",
    "    loss_i = compute_loss(logits, real_answer)\n",
    "    train_history.append((i, loss_i.detach().cpu().numpy()))\n",
    "    \n",
    "    loss_i.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
    "        if len(dev_history):\n",
    "            plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
    "        plt.legend(); plt.grid(); plt.show()\n",
    "        print(\"Generated examples (tau=0.5):\")\n",
    "        print (loss_i)\n",
    "        for j in range(3):\n",
    "            print(generate(rnn_lm1, temperature=0.5))\n",
    "    \n",
    "    if (i + 1) % score_dev_every == 0:\n",
    "        print(\"Scoring dev...\")\n",
    "        dev_history.append((i, score_lines(dev_lines, batch_size, rnn_lm1)))\n",
    "        print('#%i Dev loss: %.3f' % dev_history[-1])\n",
    "    del logits, input_seq, loss_i"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar4_lm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
