{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "translation_torch_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "edk_oVg0lrtW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HmsFABwClrsS"
      },
      "source": [
        "## Seminar 6\n",
        "\n",
        "This seminar is based on https://github.com/yandexdataschool/nlp_course/tree/2019/week04_seq2seq\n",
        "\n",
        "Today we compose the encoder-decoder neural networks and apply them to the task of machine translation.\n",
        "\n",
        "![img](https://esciencegroup.files.wordpress.com/2016/03/seq2seq.jpg)\n",
        "_(img: esciencegroup.files.wordpress.com)_\n",
        "\n",
        "\n",
        "Encoder-decoder architectures are about converting anything to anything, including\n",
        " * Machine translation and spoken dialogue systems\n",
        " * [Image captioning](http://mscoco.org/dataset/#captions-challenge2015) and [image2latex](https://openai.com/requests-for-research/#im2latex) (convolutional encoder, recurrent decoder)\n",
        " * Generating [images by captions](https://arxiv.org/abs/1511.02793) (recurrent encoder, convolutional decoder)\n",
        " * Grapheme2phoneme - convert words to transcripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R4N9AD2dlrsU"
      },
      "source": [
        "## Our task: machine translation\n",
        "\n",
        "We gonna try our encoder-decoder models on Russian to English machine translation problem. More specifically, we'll translate hotel and hostel descriptions. This task shows the scale of machine translation while not requiring you to train your model for weeks if you don't use GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBH5O-whKyU",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEkHrcJ8j9tT",
        "colab_type": "text"
      },
      "source": [
        "Install an additional **subword-nmt** package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reoLSnzfj7Ui",
        "colab_type": "code",
        "outputId": "d2bdfe0e-f29f-4f61-e69b-509440591bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#if you run in collab, uncomment this\n",
        "! pip install subword_nmt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: subword_nmt in /usr/local/lib/python3.6/dist-packages (0.3.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8moeM-qUhKSu",
        "colab_type": "code",
        "outputId": "48daf8d3-c8ca-4032-8d7b-3bd40017b2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from subword_nmt.learn_bpe import learn_bpe\n",
        "from subword_nmt.apply_bpe import BPE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QNxnha3l7Zql"
      },
      "source": [
        "## Data and preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "povwCKaONE6E"
      },
      "source": [
        "Before we get to the architecture, we do some preprocessing.\n",
        "\n",
        "1) The data will be tokenized with __WordPunctTokenizer__.\n",
        "\n",
        "2) Create a dictionary (remember the previous seminar about Language Modelling)\n",
        "\n",
        "But dictionary of what?\n",
        "\n",
        "Our data lines contain unique rare words. If we operate on a word-level, we will have to deal with large vocabulary size. If instead, we use character-level models, it would take lots of iterations to process a sequence. This time we're gonna pick something in between.\n",
        "One popular approach is called Byte Pair Encoding aka BPE. The algorithm starts with character-level tokenization and then iteratively merges most frequent pairs for N iterations. This results in frequent words being merged into a single token and rare words split into syllables or even characters.\n",
        "\n",
        "After preprocessing, we obtain files __\\*.bpe.\\*__ with tourists texts, splitting to BPE-tokens, and files of rules, which describes how every word in the vocabulary is split to tokens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CfvojjHQlrsU",
        "outputId": "4440e0a9-f6cb-4b2e-b7d2-bef21258931c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# uncomment this in collab\n",
        "!wget https://www.dropbox.com/s/yy2zqh34dyhv07i/data.txt?dl=1 -O data.txt\n",
        "!wget https://www.dropbox.com/s/fj9w01embfxvtw1/dummy_checkpoint.npz?dl=1 -O dummy_checkpoint.npz\n",
        "!wget --no-check-certificate -r 'https://docs.google.com/uc?export=download&id=1op5MWlEiroEAXxsMR6AUkdNuG634JzYc' -O utils.py\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-04 16:50:11--  https://www.dropbox.com/s/yy2zqh34dyhv07i/data.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/yy2zqh34dyhv07i/data.txt [following]\n",
            "--2019-12-04 16:50:11--  https://www.dropbox.com/s/dl/yy2zqh34dyhv07i/data.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf8492952df9c9fc7b940b06a07.dl.dropboxusercontent.com/cd/0/get/AtnacyBjj1ldqMRGLWMPH82HXa4oTsdTps6FydbZ2T7xVYpanPYk8EwCpAX_BYwRrz92IcRVVypQqAKfWgeTf5e8_Upja8SqONLFIKKh0TXUXw/file?dl=1# [following]\n",
            "--2019-12-04 16:50:11--  https://ucf8492952df9c9fc7b940b06a07.dl.dropboxusercontent.com/cd/0/get/AtnacyBjj1ldqMRGLWMPH82HXa4oTsdTps6FydbZ2T7xVYpanPYk8EwCpAX_BYwRrz92IcRVVypQqAKfWgeTf5e8_Upja8SqONLFIKKh0TXUXw/file?dl=1\n",
            "Resolving ucf8492952df9c9fc7b940b06a07.dl.dropboxusercontent.com (ucf8492952df9c9fc7b940b06a07.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to ucf8492952df9c9fc7b940b06a07.dl.dropboxusercontent.com (ucf8492952df9c9fc7b940b06a07.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12905335 (12M) [application/binary]\n",
            "Saving to: ‘data.txt’\n",
            "\n",
            "data.txt            100%[===================>]  12.31M   789KB/s    in 16s     \n",
            "\n",
            "2019-12-04 16:50:28 (786 KB/s) - ‘data.txt’ saved [12905335/12905335]\n",
            "\n",
            "--2019-12-04 16:50:29--  https://www.dropbox.com/s/fj9w01embfxvtw1/dummy_checkpoint.npz?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/fj9w01embfxvtw1/dummy_checkpoint.npz [following]\n",
            "--2019-12-04 16:50:30--  https://www.dropbox.com/s/dl/fj9w01embfxvtw1/dummy_checkpoint.npz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc72fee547fc5d95d2781866fa48.dl.dropboxusercontent.com/cd/0/get/AtkbAXAyRfrTgzRP8i2P-Gcpqr3TTNEgRkhTMQsCCwBQHsn3clbQ69FzJ7Z2zb1EpOgMNPq4-Th5D12O64rjUPkKFNGz0dC4C3ETzdcMNwgmiQ/file?dl=1# [following]\n",
            "--2019-12-04 16:50:30--  https://uc72fee547fc5d95d2781866fa48.dl.dropboxusercontent.com/cd/0/get/AtkbAXAyRfrTgzRP8i2P-Gcpqr3TTNEgRkhTMQsCCwBQHsn3clbQ69FzJ7Z2zb1EpOgMNPq4-Th5D12O64rjUPkKFNGz0dC4C3ETzdcMNwgmiQ/file?dl=1\n",
            "Resolving uc72fee547fc5d95d2781866fa48.dl.dropboxusercontent.com (uc72fee547fc5d95d2781866fa48.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc72fee547fc5d95d2781866fa48.dl.dropboxusercontent.com (uc72fee547fc5d95d2781866fa48.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8745474 (8.3M) [application/binary]\n",
            "Saving to: ‘dummy_checkpoint.npz’\n",
            "\n",
            "dummy_checkpoint.np 100%[===================>]   8.34M   741KB/s    in 12s     \n",
            "\n",
            "2019-12-04 16:50:42 (732 KB/s) - ‘dummy_checkpoint.npz’ saved [8745474/8745474]\n",
            "\n",
            "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
            "will be placed in the single file you specified.\n",
            "\n",
            "--2019-12-04 16:50:44--  https://docs.google.com/uc?export=download&id=1op5MWlEiroEAXxsMR6AUkdNuG634JzYc\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.79.113, 173.194.79.101, 173.194.79.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.79.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-6s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/abue76j3ir2hfcjtqgkmg79jefa7qq4h/1575475200000/01961971800886548445/*/1op5MWlEiroEAXxsMR6AUkdNuG634JzYc?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2019-12-04 16:50:44--  https://doc-0s-6s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/abue76j3ir2hfcjtqgkmg79jefa7qq4h/1575475200000/01961971800886548445/*/1op5MWlEiroEAXxsMR6AUkdNuG634JzYc?e=download\n",
            "Resolving doc-0s-6s-docs.googleusercontent.com (doc-0s-6s-docs.googleusercontent.com)... 108.177.126.132, 2a00:1450:4013:c01::84\n",
            "Connecting to doc-0s-6s-docs.googleusercontent.com (doc-0s-6s-docs.googleusercontent.com)|108.177.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4677 (4.6K) [text/x-python]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-12-04 16:50:45 (90.2 MB/s) - ‘utils.py’ saved [4677/4677]\n",
            "\n",
            "FINISHED --2019-12-04 16:50:45--\n",
            "Total wall clock time: 0.6s\n",
            "Downloaded: 1 files, 4.6K in 0s (90.2 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g9kP0SdxlrsY",
        "colab": {}
      },
      "source": [
        "tokenizer = WordPunctTokenizer()\n",
        "def tokenize(x):\n",
        "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
        "\n",
        "# split and tokenize the data\n",
        "with open('train.en', 'w') as f_src,  open('train.ru', 'w') as f_dst:\n",
        "    for line in open('data.txt'):\n",
        "        src_line, dst_line = line.strip().split('\\t')\n",
        "        f_src.write(tokenize(src_line) + '\\n')\n",
        "        f_dst.write(tokenize(dst_line) + '\\n')\n",
        "\n",
        "# build and apply bpe vocs\n",
        "bpe = {}\n",
        "for lang in ['en', 'ru']:\n",
        "    learn_bpe(open('./train.' + lang), open('bpe_rules.' + lang, 'w'), num_symbols=8000)\n",
        "    bpe[lang] = BPE(open('./bpe_rules.' + lang))\n",
        "    \n",
        "    with open('train.bpe.' + lang, 'w') as f_out:\n",
        "        for line in open('train.' + lang):\n",
        "            f_out.write(bpe[lang].process_line(line.strip()) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FUjpP3l5UyHu",
        "outputId": "a5ace381-77b6-46ff-a4c4-a3fe55aeab1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "!head train.bpe.en | tee head.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cor@@ del@@ ia hotel is situated in tbilisi , a 3 - minute walk away from saint trinity church .\n",
            "at tu@@ pi@@ r@@ mar@@ ka lodge you will find a 24 - hour front desk , room service , and a snack bar .\n",
            "featuring free wifi in all areas , nai@@ g@@ ao xiao@@ wo offers accommodation in shanghai .\n",
            "each has a tv and a private bathroom with shower .\n",
            "your room comes with air conditioning and satellite tv .\n",
            "they are styled in cream - coloured hu@@ es and some of them feature private balconies with seating areas .\n",
            "the reception team can help guests plan sightseeing trips .\n",
            "some units include a seating area for your convenience .\n",
            "ni@@ eu@@ w@@ markt as well as kal@@ ver@@ straat , hermitage and rem@@ brand@@ t@@ plein are within 15 minutes walking .\n",
            "the danube delta is a natural reserve where you can go fishing , bird watching , take boat rides or simply unwind surrounded by nature .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbFR0wsahFFQ",
        "colab_type": "text"
      },
      "source": [
        "### Split to train-dev\n",
        "..and look at examples of data in train and dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8PskgBSxlrsd",
        "outputId": "9d9f8d7d-c8c7-4f3b-caaf-2e27c155b28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "data_inp = np.array(open('./train.bpe.ru').read().split('\\n'))\n",
        "data_out = np.array(open('./train.bpe.en').read().split('\\n'))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,\n",
        "                                                          random_state=42)\n",
        "for i in range(3):\n",
        "    print('inp:', train_inp[i])\n",
        "    print('out:', train_out[i], end='\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: на территории обустроена бесплатная частная парковка .\n",
            "out: free private parking is available on site .\n",
            "\n",
            "inp: кроме того , в 5 минутах ходьбы работают многочисленные бары и рестораны .\n",
            "out: guests can find many bars and restaurants within a 5 - minute walk .\n",
            "\n",
            "inp: отель san mi@@ gu@@ el расположен в центре мор@@ ели@@ и , в 750 метрах от главной площади города и кафедрального собора .\n",
            "out: hotel san miguel is located in central more@@ lia , 750 metres from the city ’ s main square and cathedral .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE6AvYHqnSK1",
        "colab_type": "text"
      },
      "source": [
        "### Building vocabularies\n",
        "\n",
        "In seminar 4 we build a vocabulary over tokens. \n",
        "\n",
        "On vocabulary base (**ids_to_token, token_to_ids**) we provide **to_matrix** function. Now this function and vocab class are in **util.py**. Besides **to_matrix** we provide **matrix_to_line**, which corresponds matrix of token indices to real line. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hd-egkNANE6g"
      },
      "source": [
        "__Vocab__ class and and its functionality works like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSwq7RjBoKSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import Vocab\n",
        "\n",
        "inp_voc = Vocab.from_lines(train_inp)\n",
        "out_voc = Vocab.from_lines(train_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyIeMP5crDFr",
        "colab_type": "text"
      },
      "source": [
        "Here's how you cast lines into ids and backwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cwOoHfuhlrsi",
        "outputId": "2ae1a021-bc29-4bae-e34a-bf3605c27e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "batch_lines = sorted(train_inp, key=len)[5:10]\n",
        "batch_ids = inp_voc.to_matrix(batch_lines)\n",
        "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
        "\n",
        "print(\"lines\")\n",
        "print(batch_lines)\n",
        "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
        "print(batch_ids)\n",
        "print(\"\\nback to words\")\n",
        "print(batch_lines_restored)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines\n",
            "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n",
            "\n",
            "words to ids (0 = bos, 1 = eos):\n",
            "[[   0 2688 2943 1108   29    1    1    1]\n",
            " [   0 2922 1834 8035   59 3800   29    1]\n",
            " [   0 6030 2083   29    1    1    1    1]\n",
            " [   0 4927 1870   29    1    1    1    1]\n",
            " [   0 5549 1453   27  592   29    1    1]]\n",
            "\n",
            "back to words\n",
            "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQvafAZ_sGuh",
        "colab_type": "text"
      },
      "source": [
        "We also define functions to compute lengths of every line in batch and create a mask for inference based on it (as in __seminar4__)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej73IpiOo1F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_mask(lengths, maxlen, dtype=torch.bool):\n",
        "    \"\"\"\n",
        "    :param lenghts: array of size K, lenghts of input K lines\n",
        "    :param maxlen: number of steps in our case\n",
        "    \"\"\"\n",
        "    if maxlen is None:\n",
        "        maxlen = lengths.max()\n",
        "    cuda_check = lengths.is_cuda\n",
        "    if cuda_check:\n",
        "        cuda_device = lengths.get_device()\n",
        "    \n",
        "    one_tensor = torch.ones((len(lengths), maxlen))\n",
        "    if (cuda_check):\n",
        "        one_tensor = one_tensor.cuda(device=cuda_device)\n",
        "    \n",
        "    mask = ~(one_tensor.cumsum(dim=1).t() > lengths).t()\n",
        "    mask.type(dtype)\n",
        "    return mask\n",
        "\n",
        "def infer_length(input_ix, eos_ix, time_major=False):\n",
        "    \"\"\" compute length of each line in input ix (incl. first EOS), int32 vector of shape [batch_size] \"\"\"\n",
        "    \"\"\" Cont number of non-zero indexes \"\"\"\n",
        "    axis = 0 if time_major else 1\n",
        "    a = input_ix.eq(eos_ix)\n",
        "    count_eos = torch.cumsum(a, axis)\n",
        "    lengths = torch.sum(count_eos.eq(0), axis)\n",
        "    return lengths + 1 \n",
        "\n",
        "def infer_mask(seq, eos_ix, time_major=False):\n",
        "    \"\"\"\n",
        "    compute mask given output indices and eos code\n",
        "    :param seq: tf matrix [time,batch] if time_major else [batch,time]\n",
        "    :param eos_ix: integer index of end-of-sentence token\n",
        "    :returns: mask, float32 matrix with '0's and '1's of same shape as seq\n",
        "    \"\"\"\n",
        "    axis = 0 if time_major else 1\n",
        "    lengths = infer_length(seq, eos_ix, time_major=time_major)\n",
        "    mask = sequence_mask(lengths, maxlen=seq.size()[axis])\n",
        "    if time_major: mask = mask.transpose(1, 0)\n",
        "    return mask\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BHWgx34flrsn"
      },
      "source": [
        "### Simple encoder-decoder model\n",
        "\n",
        "* The picture below contains a scheme for a simple encoder-decoder model: single GRU encoder/decoder, no attention or anything.\n",
        "\n",
        "* The chain between encoder and decoder: In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "txK05B4M7ZrG"
      },
      "source": [
        "![img](https://docs.google.com/uc?export=download&id=1srrm_If8MMWVoUl-qEJ1ieteC5dAwvhm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZMBfsE1n4aU",
        "colab_type": "text"
      },
      "source": [
        "* TRAIN MODE\n",
        "\n",
        "When we train model and target lines are known, __out[i]__ is a i-th token from the corresponding target line.\n",
        "It is function __decode()__ in the model below.\n",
        "\n",
        "* GENERATE MODE\n",
        "\n",
        "__out[i]__ is a previously generated token, obtain from previous logits (by __argmax__, for example) \n",
        "It is function __decode_inference()__\n",
        "\n",
        "The picture describes **TRAIN_MODE**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wgfN5-F7lrst",
        "colab": {}
      },
      "source": [
        "class BasicModel(nn.Module):\n",
        "    def __init__(self, inp_voc, out_voc, device, emb_size=64, hid_size=128):\n",
        "        \"\"\"\n",
        "        A simple encoder-decoder model\n",
        "        \"\"\"\n",
        "        super().__init__() \n",
        "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
        "        self.hid_size = hid_size\n",
        "\n",
        "        # your code here\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "    def initHidden(self, batch_size):\n",
        "        return torch.zeros(1, batch_size, self.hid_size)\n",
        "\n",
        "    def encode(self, inp, **flags):\n",
        "        \"\"\"\n",
        "        Takes symbolic input sequence, computes initial state\n",
        "        :param inp: matrix of input tokens [batch, time]\n",
        "        :returns: initial decoder state tensors, one or many\n",
        "        \"\"\"\n",
        "        \n",
        "        # your code here\n",
        "        \n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
        "        \"\"\"\n",
        "        Takes previous decoder state and tokens, returns new state and logits for next tokens\n",
        "        :param prev_state: a list of previous decoder state tensors\n",
        "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
        "        :return: a list of next decoder state tensors, a tensor of logits [batch, n_tokens]\n",
        "        \"\"\"\n",
        "\n",
        "        prev_tokens = torch.unsqueeze(prev_tokens, 1)\n",
        "        \n",
        "        # your code here\n",
        "        \n",
        "        return new_dec_state, output_logits\n",
        "\n",
        "    def decode(self, initial_state, out_tokens, **flags):\n",
        "        \"\"\" Run decoder on reference tokens (out_tokens) \"\"\"\n",
        "        \"\"\" TRAIN MODE \"\"\"\n",
        "        state = initial_state\n",
        "        batch_size = out_tokens.shape[0]\n",
        "\n",
        "        # initial logits: always predict BOS\n",
        "        first_logits = torch.ones((batch_size, 1), dtype=torch.long).fill_(self.out_voc.bos_ix)\n",
        "\n",
        "        first_logits_onehot = torch.Tensor(batch_size, len(self.out_voc)).zero_()\n",
        "\n",
        "        first_logits_onehot.scatter_(1, first_logits, 1)\n",
        "        \n",
        "        first_logits = torch.log(first_logits_onehot + 1e-30).to(device)\n",
        "\n",
        "        outputs = [torch.unsqueeze(first_logits, 1)]\n",
        "        for i in range(out_tokens.shape[1] - 1):\n",
        "            # your code here\n",
        "            outputs.append(logits)\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "    def forward(self, inp, out):\n",
        "        \"\"\" Apply model in training mode \"\"\"\n",
        "        encoder_output, encoder_hidden = self.encode(inp)\n",
        "        \n",
        "        return self.decode(encoder_hidden, out)\n",
        "\n",
        "    def decode_inference(self, initial_state, max_len=100, **flags):\n",
        "        \"\"\" Generate translations from model (greedy version) \"\"\"\n",
        "        \"\"\" GENERATE MODE \"\"\"\n",
        "        state = initial_state\n",
        "        prev_elems = torch.ones(initial_state[0].shape[0]).to(self.device).to(torch.int64) * self.out_voc.bos_ix\n",
        "        outputs = [prev_elems.unsqueeze(1)]\n",
        "        all_states = [initial_state]\n",
        "        for i in range(max_len):\n",
        "            # your code here\n",
        "            all_states.append(state)\n",
        "        return torch.cat(outputs, 1), all_states\n",
        "\n",
        "    def translate_lines(self, inp_lines):\n",
        "        encoder_output, encoder_hidden = self.encode(inp_lines)\n",
        "        out_ids, states = self.decode_inference(encoder_hidden)\n",
        "        return out_voc.to_lines(out_ids.cpu().detach().numpy()), states\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9fNcvlfpa4Y",
        "colab_type": "text"
      },
      "source": [
        "Test model creation and logits prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_aGkMAU0BtB6",
        "outputId": "5499765d-b4d2-4eac-9113-8db4a67e66b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\") \n",
        "model = BasicModel(inp_voc, out_voc, device)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BasicModel(\n",
              "  (emb_inp): Embedding(8048, 64)\n",
              "  (emb_out): Embedding(7801, 64)\n",
              "  (enc0): GRU(64, 128, batch_first=True)\n",
              "  (dec0): GRU(64, 128, batch_first=True)\n",
              "  (dec_dense): Linear(in_features=128, out_features=7801, bias=True)\n",
              "  (logits): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Cmv9Lrulrs3",
        "colab": {}
      },
      "source": [
        "dummy_inp = torch.tensor(inp_voc.to_matrix(train_inp[:3])).to(torch.int64)\n",
        "dummy_out = torch.tensor(out_voc.to_matrix(train_out[:3])).to(torch.int64)\n",
        "dummy_logits = model(dummy_inp.to(device), dummy_out.to(device))\n",
        "ref_shape = (dummy_out.shape[0], dummy_out.shape[1], len(out_voc))\n",
        "assert dummy_logits.shape == ref_shape, \"Your logits shape should be {} but got {}\".format(dummy_logits.shape, ref_shape)\n",
        "assert all(dummy_logits[:, 0].cpu().detach().numpy().argmax(-1) == out_voc.bos_ix), \"first step must always be BOS\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jTn6oEIs7ZrT",
        "outputId": "b52b19a3-1d9d-419d-84e8-2d805147add0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dummy_inp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_wuv1-aVlrs0"
      },
      "source": [
        "### Training loss\n",
        "\n",
        "Our training objetive is almost the same as it was for neural language models:\n",
        "$$ L = {\\frac1{|D|}} \\sum_{X, Y \\in D} \\sum_{y_t \\in Y} - \\log p(y_t \\mid y_1, \\dots, y_{t-1}, X, \\theta) $$\n",
        "\n",
        "where $|D|$ is the __total length of all sequences__, including BOS and first EOS, but excluding PAD.\n",
        "\n",
        "This loss is similar to ones in 4th seminar, but:\n",
        "\n",
        "* instead of sum up over the sequence and than average between all lines in batch we __sum up token losses__ (excluding PAD tokens!) in all batch and __divide it to number of non-pad tokens__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c8XPV8sWlrs5",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "def compute_loss(model, inp, out, **flags):\n",
        "    \"\"\"\n",
        "    Compute loss (float32 scalar) as in the formula above\n",
        "    :param inp: input tokens matrix, int32[batch, time]\n",
        "    :param out: reference tokens matrix, int32[batch, time]\n",
        "    \n",
        "    In order to pass the tests, your function should\n",
        "    * include loss at first EOS but not the subsequent ones\n",
        "    * divide sum of losses by a sum of input lengths (use infer_length or infer_mask)\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    # your code here\n",
        "    \n",
        "    return   # scalar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ME_LWUeklrs7",
        "outputId": "24b629ca-9e46-4008-d319-67f87cce8061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dummy_loss = compute_loss(model, dummy_inp.to(device), dummy_out.to(device))\n",
        "print(\"Loss:\", dummy_loss)\n",
        "assert np.allclose(dummy_loss.cpu().detach().numpy(), 8.425, rtol=0.1, atol=0.1), \"We're sorry for your loss\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: tensor(8.4400, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HpbaBpW7lrs-"
      },
      "source": [
        "### Evaluation: BLEU\n",
        "\n",
        "Machine translation is commonly evaluated with [BLEU](https://en.wikipedia.org/wiki/BLEU) score. This metric simply computes which fraction of predicted n-grams is actually present in the reference translation. It does so for n=1,2,3 and 4 and computes the geometric average with penalty if translation is shorter than reference.\n",
        "\n",
        "While BLEU [has many drawbacks](http://www.cs.jhu.edu/~ccb/publications/re-evaluating-the-role-of-bleu-in-mt-research.pdf), it still remains the most commonly used metric and one of the simplest to compute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gb1-PhKIlrs-",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "def compute_bleu(model, inp_lines, out_lines, bpe_sep='@@ ', **flags):\n",
        "    \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
        "    dev_inp_tensor = torch.tensor(inp_voc.to_matrix(inp_lines)).to(torch.int64).to(device)\n",
        "    # your code here\n",
        "    del dev_inp_tensor\n",
        "    # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
        "    return corpus_bleu(\n",
        "        # your code here)\n",
        "        \n",
        "## HINT: smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06A_ySdX6ATI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZvfid1RlrtA",
        "outputId": "214a11cd-6545-4fad-d52e-295544472987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "compute_bleu(model, dev_inp, dev_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0018273646763056592"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nQDhGwg4lrtC"
      },
      "source": [
        "### Training parameters\n",
        "\n",
        "Training encoder-decoder models isn't that different from any other models: sample batches, compute loss, backprop and update\n",
        "\n",
        "Set optimizer, batch_size, vocabulary for loss and metrics for visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yfwIaixHlrtI",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm, trange\n",
        "metrics = {'train_loss': [], 'dev_bleu': [] }\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZvO5q3r7iTnS",
        "outputId": "bc1ebc56-6a69-4e99-d7c2-8e76cad9c6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Loss:\", dummy_loss.cpu().detach().item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 8.417143821716309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1okxXE0tiTnV",
        "outputId": "05d34d91-7a96-42e6-f2f6-9ea57cc1a26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "metrics['dev_bleu'].append(compute_bleu(model, dev_inp, dev_out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B6EWvgm17Zr0"
      },
      "source": [
        "## Training \n",
        "To achieve reasonable results, it is enough to do 5000 iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LlDT6eDUlrtL",
        "outputId": "1dbbb455-40a0-42a6-ee6b-db51d00e157f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        }
      },
      "source": [
        "metrics = {'train_loss': [], 'dev_bleu': [] }\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "for _ in trange(25000):\n",
        "    step = len(metrics['train_loss']) + 1\n",
        "    batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
        "    batch_inp = torch.tensor(inp_voc.to_matrix(train_inp[batch_ix])).to(torch.int64).to(device)\n",
        "    batch_out = torch.tensor(out_voc.to_matrix(train_out[batch_ix])).to(torch.int64).to(device)\n",
        "    optimizer.zero_grad()\n",
        "    loss_i = compute_loss(model, batch_inp, batch_out)\n",
        "    print(loss_i.cpu().detach().item())\n",
        "    metrics['train_loss'].append(loss_i.cpu().detach().item())\n",
        "    \n",
        "    if step % 200 == 0:\n",
        "        metrics['dev_bleu'].append(compute_bleu(model, dev_inp, dev_out))\n",
        "        \n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(12,4))\n",
        "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
        "            plt.subplot(1, len(metrics), i + 1)\n",
        "            plt.title(name)\n",
        "            plt.plot(history)\n",
        "            plt.grid()\n",
        "        plt.show()\n",
        "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0), flush=True)\n",
        "        \n",
        "    loss_i.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "        \n",
        "# Note: it's okay if bleu oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAEICAYAAACgdxkmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Mean loss=3.694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 400/25000 [07:36<59:50:03,  8.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.9790327548980713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 401/25000 [07:38<44:20:30,  6.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.33984375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 402/25000 [07:39<33:02:00,  4.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.2815730571746826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 403/25000 [07:40<25:14:58,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.466057777404785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 404/25000 [07:41<19:42:33,  2.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.93691349029541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 405/25000 [07:41<15:18:48,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.3605897426605225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 406/25000 [07:42<12:37:50,  1.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-afd6e320e6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_voc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-af6245271c24>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(model, inp, out, **flags)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mlogits_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# size [batch, num_of_step]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UFpE-liU2hK0",
        "outputId": "5046d80d-19e9-48d7-f2e9-241a275ab524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(metrics['train_loss'][-10:], axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5971691608428955"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ahuhKVhlrtP",
        "outputId": "14015e06-9670-4822-995e-b28fa7a74490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(metrics['dev_bleu'][-10:], axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4321797708537967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AEnHKg4x6cvR"
      },
      "source": [
        "**Look at the translation.**\n",
        "**Not bad, but not brilliant**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyaHOpealrtS",
        "outputId": "10764530-6626-4f0c-d17e-c319a93902bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "dev_inp_tensor = torch.tensor(inp_voc.to_matrix(dev_inp[::500])).to(torch.int64).to(device)\n",
        "for inp_line, trans_line in zip(dev_inp[::500], model.translate_lines(dev_inp_tensor)[0]):\n",
        "    print(inp_line)\n",
        "    print(trans_line)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "в распоряжении гостей общая кухня и общая гостиная .\n",
            "the property offers free parking .\n",
            "\n",
            "кроме того , предоставляется прокат велосипедов , услуги трансфера и бесплатная парковка .\n",
            "the property offers free parking .\n",
            "\n",
            "расстояние до города ки@@ сси@@ м@@ ми составляет 26 км .\n",
            "the nearest airport is a 15 - minute drive away .\n",
            "\n",
            "апартаменты в пент@@ хаусе с общим открытым бассейном , садом , кондиционером и террасой для загара расположены в 5 минутах ходьбы от пляжа на курорте ка@@ бо - рой .\n",
            "the property is a 5 - minute walk from the beach , while the nearest airport is located in the property .\n",
            "\n",
            "апартаменты mo@@ s@@ co@@ w point - loft red square находятся в москве , в 200 метрах от большого театра .\n",
            "the nearest airport is located in the property .\n",
            "\n",
            "в вашем распоряжении собственная ванная комната с душем и полотенцами .\n",
            "the property has a shower .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tv0s8qxOXp5y"
      },
      "source": [
        "# Attention ... is all you need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvZidckAYQxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "0be8bdb7-f63a-4eca-dcb2-76e8fefab662"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/attention_mechanism.gif')  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/attention_mechanism.gif\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edk_oVg0lrtW"
      },
      "source": [
        "### Your Attention Required\n",
        "\n",
        "In this section we want you to improve over the basic model by implementing a simple attention mechanism.\n",
        "\n",
        "This is gonna be a two-parter: building the __attention layer__ and using it for an __attentive seq2seq model__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qz9aROAIlrtX"
      },
      "source": [
        "### Attention layer\n",
        "\n",
        "Here you will have to implement a layer that computes a simple additive attention:\n",
        "\n",
        "Given encoder sequence $ h^e_0, h^e_1, h^e_2, ..., h^e_T$ and a single decoder state $h^d$,\n",
        "\n",
        "* Compute logits with a 2-layer neural network\n",
        "$$a_t = linear_{out}(tanh(linear_{e}(h^e_t) + linear_{d}(h_d)))$$\n",
        "* Get probabilities from logits, \n",
        "$$ p_t = {{e ^ {a_t}} \\over { \\sum_\\tau e^{a_\\tau} }} $$\n",
        "\n",
        "* Add up encoder states with probabilities to get __attention response__\n",
        "$$ attn = \\sum_t p_t \\cdot h^e_t $$\n",
        "\n",
        "You can learn more about attention layers in the leсture slides or [from this post] (https://distill.pub/2016/augmented-rnns/) or from [here],(https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
        "\n",
        "class __AttentionLayer__ works in __decode_step__ in common model.\n",
        "\n",
        "* Input parameters:\n",
        "\n",
        "  __enc_size__, __dec_size__ - size of hidden states from encoder and decoder respectively. Not equal in common case\n",
        "  \n",
        "  __hid_size__ - size of a_t \n",
        "  \n",
        "  __enc__ - all sequence of **hidden_states** from encoder, bs * seq_len * enc_size\n",
        "  \n",
        "  __dec__ -  **hidden_state** from decoder, bs * dec_size\n",
        "  \n",
        "* Input parameters:\n",
        "\n",
        "    __probas__ - weighst of every encoder state consider the decoder, *p_t*\n",
        "    \n",
        "    __attn__ - the weighted sum of encoder states, *attn*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cwpl-phb2JOT",
        "colab": {}
      },
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, name, enc_size, dec_size, hid_size):\n",
        "        \"\"\" A layer that computes additive attention response and weights \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc_size = enc_size \n",
        "        self.dec_size = dec_size \n",
        "        self.hid_size = hid_size \n",
        "        self.activ = nn.Tanh()  \n",
        "\n",
        "        self.linear_enc = #your code here\n",
        "        self.linear_dec = #your code here\n",
        "        self.linear_out = #your code here\n",
        "        \n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, enc, dec, inp_mask):\n",
        "        \"\"\"\n",
        "        Computes attention response and weights\n",
        "        :param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\n",
        "        :param dec: single decoder state used as \"query\", float32[batch_size, dec_size]\n",
        "        :param inp_mask: mask on enc activatons (0 after first eos), float32 [batch_size, ninp]\n",
        "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
        "            - attn - attention response vector (weighted sum of enc)\n",
        "            - probs - attention weights after softmax\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        # Compute logits\n",
        "        \n",
        "        # your code here\n",
        "        \n",
        "        # Apply mask - if mask is 0, logits should be -inf or -1e9\n",
        "        \n",
        "        # your code here\n",
        "        \n",
        "        # Compute attention probabilities (softmax)\n",
        "        \n",
        "        # your code here\n",
        "        \n",
        "        # Compute attention response using enc and probs\n",
        "        \n",
        "\n",
        "        return attn, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-VM_PtHG7ZsP",
        "colab": {}
      },
      "source": [
        "m = AttentionLayer(\"my_sweet_attn\", 128, 128, 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IalfpdAelrtb"
      },
      "source": [
        "### Seq2seq model with attention\n",
        "\n",
        "You can now use the attention layer to build a network. The simplest way to implement attention is to use it in decoder phase:\n",
        "![img](https://i.imgur.com/6fKHlHb.png)\n",
        "_image from distill.pub [article](https://distill.pub/2016/augmented-rnns/)_\n",
        "\n",
        "On every step, use __previous__ decoder state to obtain attention response. Then feed concat this response to the inputs of next attetion layer.\n",
        "\n",
        "The key implementation detail here is __model state__. Put simply, you can add any tensor into the list of `encode` outputs. You will then have access to them at each `decode` step. This may include:\n",
        "* Last RNN hidden states (as in basic model)\n",
        "* The whole sequence of encoder outputs (to attend to) and mask\n",
        "* Attention probabilities (to visualize)\n",
        "\n",
        "_There are, of course, alternative ways to wire attention into your network and different kinds of attention. Take a look at [this](https://arxiv.org/abs/1609.08144), [this](https://arxiv.org/abs/1706.03762) and [this](https://arxiv.org/abs/1808.03867) for ideas. And for image captioning/im2latex there's [visual attention](https://arxiv.org/abs/1502.03044)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zFd0Usl47ZsU",
        "colab": {}
      },
      "source": [
        "class AttentiveModelLayer(BasicModel):\n",
        "    def __init__(self, inp_voc, out_voc, device, emb_size=64, hid_size=128, attn_size = 128):\n",
        "        \"\"\"\n",
        "        A simple encoder-decoder model\n",
        "        \"\"\"\n",
        "        super().__init__(inp_voc, out_voc, device) # initialize base class to track sub-layers, trainable variables, etc.\n",
        "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
        "        self.hid_size = hid_size\n",
        "\n",
        "        # your code here\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.l_attention = AttentionLayer(\"Attention\", hid_size, hid_size, attn_size)\n",
        "\n",
        "    def encode(self, inp, **flags):\n",
        "        \"\"\"\n",
        "        Takes symbolic input sequence, computes initial state\n",
        "        :param inp: matrix of input tokens [batch, time]\n",
        "        :returns: initial decoder state tensors, one or many\n",
        "        \"\"\"\n",
        "        # your code here\n",
        "        return output, hidden, embedded, mask\n",
        "\n",
        "\n",
        "    def decode_step(self, prev_state, encoder_sequence, mask, prev_tokens, **flags):\n",
        "        \"\"\"\n",
        "        Takes previous decoder state and tokens, returns new state and logits for next tokens\n",
        "        :param prev_state: a list of previous decoder state tensors\n",
        "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
        "        :return: a list of next decoder state tensors, a tensor of logits [batch, n_tokens]\n",
        "        \"\"\"\n",
        "\n",
        "        # your code here\n",
        "        \n",
        "        return new_dec_state, output_logits, t_probs\n",
        "\n",
        "    def decode(self, initial_state, out_tokens, **flags):\n",
        "        \"\"\" Run decoder on reference tokens (out_tokens) \"\"\"\n",
        "        \"\"\" TRAIN MODE \"\"\"\n",
        "        encoder_sequence, state, encoder_emb, mask = initial_state\n",
        "        batch_size = out_tokens.shape[0]\n",
        "\n",
        "        # initial logits: always predict BOS\n",
        "        first_logits = torch.ones((batch_size, 1), dtype=torch.long).fill_(self.out_voc.bos_ix)\n",
        "\n",
        "        first_logits_onehot = torch.Tensor(batch_size, len(self.out_voc)).zero_()\n",
        "\n",
        "        first_logits_onehot.scatter_(1, first_logits, 1)\n",
        "        \n",
        "        first_logits = torch.log(first_logits_onehot + 1e-30).to(device)\n",
        "\n",
        "        outputs = [torch.unsqueeze(first_logits, 1)]\n",
        "        aprobs = [torch.zeros(mask.shape)]\n",
        "        for i in range(out_tokens.shape[1] - 1):\n",
        "            # your code here\n",
        "            outputs.append(logits)\n",
        "            aprobs.append(aprob)\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "    def forward(self, inp, out):\n",
        "        \"\"\" Apply model in training mode \"\"\"\n",
        "        encoder_output, encoder_hidden, embedded, mask = self.encode(inp)\n",
        "        \n",
        "        return self.decode((encoder_output, encoder_hidden, embedded, mask), out)\n",
        "\n",
        "    def decode_inference(self, initial_state, max_len=100, **flags):\n",
        "        \"\"\" Generate translations from model (greedy version) \"\"\"\n",
        "        \"\"\" GENERATE MODE \"\"\"\n",
        "        encoder_sequence, state, encoder_emb, mask = initial_state\n",
        "        prev_elems = torch.ones(initial_state[0].shape[0]).to(self.device).to(torch.int64) * self.out_voc.bos_ix\n",
        "        outputs = [prev_elems.unsqueeze(1)]\n",
        "        all_states = [initial_state]\n",
        "        aprobs = [torch.zeros(mask.shape)]\n",
        "        for i in range(max_len):\n",
        "            # your code here\n",
        "            outputs.append(torch.argmax(logits, axis=-1))\n",
        "            all_states.append(state)\n",
        "            aprobs.append(aprob)\n",
        "        return torch.cat(outputs, 1), all_states, aprobs\n",
        "\n",
        "    def translate_lines(self, inp_lines):\n",
        "        encoder_information = self.encode(inp_lines)\n",
        "        out_ids, states, aprobs = self.decode_inference(encoder_information)\n",
        "        return out_voc.to_lines(out_ids.cpu().detach().numpy()), states, aprobs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JV-9GYH-7ZsW",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\") \n",
        "model = AttentiveModelLayer(inp_voc, out_voc, device)\n",
        "model.to(device)\n",
        "dummy_inp = torch.tensor(inp_voc.to_matrix(train_inp[:3])).to(torch.int64)\n",
        "dummy_out = torch.tensor(out_voc.to_matrix(train_out[:3])).to(torch.int64)\n",
        "dummy_logits = model(dummy_inp.to(device), dummy_out.to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j03z_k-E2JOX",
        "outputId": "c757cef1-9d5b-49be-8698-08eb9807c55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dummy_loss = compute_loss(model, dummy_inp, dummy_out)\n",
        "print(\"Loss:\", dummy_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: tensor(8.4232, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SO8-qswyCO5E",
        "outputId": "5f5523ed-4fec-41b4-e567-e88c93934346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "compute_bleu(model, dev_inp, dev_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-609546ca008b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbleu_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompute_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-84-4d1bbec9b4fe>\u001b[0m in \u001b[0;36mcompute_bleu\u001b[0;34m(model, inp_lines, out_lines, bpe_sep, **flags)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mdev_inp_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_voc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_inp_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mtranslations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mdev_inp_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-26fd3668a94c>\u001b[0m in \u001b[0;36mtranslate_lines\u001b[0;34m(self, inp_lines)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslate_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mencoder_information\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mout_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_information\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_voc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-26fd3668a94c>\u001b[0m in \u001b[0;36mdecode_inference\u001b[0;34m(self, initial_state, max_len, **flags)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0maprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mall_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-26fd3668a94c>\u001b[0m in \u001b[0;36mdecode_step\u001b[0;34m(self, prev_state, encoder_sequence, mask, prev_tokens, **flags)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mt_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mt_rnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dec_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_emp_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-469382e8d949>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc, dec, inp_mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Compute logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlin_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlin_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, ninp, enc_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mlin_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlin_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, 1, enc_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin_enc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlin_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# [batch, ninp, 1] or [batch, ninp]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ryZCOTEslrtf"
      },
      "source": [
        "### Training attentive model\n",
        "\n",
        "Please reuse the infrastructure you've built for the regular model. I hope you didn't hard-code anything :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nj2bDGan7Zsd",
        "outputId": "1b0a3ca1-d018-423a-c063-e4ff5b792cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "metrics = {'train_loss': [], 'dev_bleu': [] }\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "for _ in trange(25000):\n",
        "    step = len(metrics['train_loss']) + 1\n",
        "    batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
        "    batch_inp = torch.tensor(inp_voc.to_matrix(train_inp[batch_ix])).to(torch.int64).to(device)\n",
        "    batch_out = torch.tensor(out_voc.to_matrix(train_out[batch_ix])).to(torch.int64).to(device)\n",
        "    optimizer.zero_grad()\n",
        "    loss_i = compute_loss(model, batch_inp, batch_out)\n",
        "    print(loss_i.cpu().detach().item())\n",
        "    metrics['train_loss'].append(loss_i.cpu().detach().item())\n",
        "    \n",
        "    if step % 200 == 0:\n",
        "        metrics['dev_bleu'].append(compute_bleu(model, dev_inp, dev_out))\n",
        "        \n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(12,4))\n",
        "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
        "            plt.subplot(1, len(metrics), i + 1)\n",
        "            plt.title(name)\n",
        "            plt.plot(history)\n",
        "            plt.grid()\n",
        "        plt.show()\n",
        "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0), flush=True)\n",
        "        \n",
        "    loss_i.backward()\n",
        "    optimizer.step()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAEICAYAAACgdxkmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKIqiKDNExbOiKIqiKIqizJD/D+zexmRjdJScAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Mean loss=3.969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 200/25000 [04:36<106:46:31, 15.50s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.8324215412139893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 201/25000 [04:37<76:56:07, 11.17s/it] \u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.734429359436035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 202/25000 [04:38<56:04:59,  8.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.998544216156006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 203/25000 [04:40<42:05:51,  6.11s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.281213760375977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 204/25000 [04:41<31:56:17,  4.64s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.00761604309082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 205/25000 [04:42<24:57:02,  3.62s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.3542680740356445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 206/25000 [04:44<20:25:16,  2.97s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.19662618637085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 207/25000 [04:45<16:01:43,  2.33s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.584852695465088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 208/25000 [04:45<13:02:33,  1.89s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.142045021057129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 209/25000 [04:47<11:59:38,  1.74s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.9993388652801514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 210/25000 [04:48<10:59:23,  1.60s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6892364025115967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 211/25000 [04:49<9:27:09,  1.37s/it] \u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.9879612922668457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 212/25000 [04:50<8:59:15,  1.31s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.668619394302368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 213/25000 [04:51<8:14:06,  1.20s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.037206172943115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 214/25000 [04:52<7:51:14,  1.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.8864471912384033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 215/25000 [04:53<8:11:56,  1.19s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.026228427886963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 216/25000 [04:54<7:39:14,  1.11s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.8626279830932617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 217/25000 [04:56<8:01:16,  1.17s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.839902400970459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 218/25000 [04:56<7:34:28,  1.10s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.006775856018066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 219/25000 [04:58<7:27:33,  1.08s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.8136446475982666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 220/25000 [04:59<7:22:37,  1.07s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.2519097328186035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 221/25000 [05:00<7:33:50,  1.10s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6178998947143555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 222/25000 [05:01<7:37:11,  1.11s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.891502857208252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 223/25000 [05:02<7:28:59,  1.09s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.9915871620178223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 224/25000 [05:03<7:29:42,  1.09s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.106388568878174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 225/25000 [05:04<7:51:12,  1.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.760352373123169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 226/25000 [05:05<7:09:55,  1.04s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6772971153259277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 227/25000 [05:06<7:30:33,  1.09s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.447758197784424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 228/25000 [05:08<7:51:38,  1.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.00049352645874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 229/25000 [05:08<7:27:34,  1.08s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.78666353225708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 230/25000 [05:10<7:40:40,  1.12s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6633687019348145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 231/25000 [05:11<7:41:50,  1.12s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.858546495437622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 232/25000 [05:12<7:39:33,  1.11s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.5678582191467285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 233/25000 [05:13<8:14:13,  1.20s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.2826690673828125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 234/25000 [05:14<8:09:15,  1.19s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.8461251258850098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 235/25000 [05:16<8:23:15,  1.22s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.5186288356781006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 236/25000 [05:17<8:00:56,  1.17s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.032811641693115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 237/25000 [05:18<8:01:29,  1.17s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.1587257385253906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 238/25000 [05:19<8:29:40,  1.23s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.380850315093994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 239/25000 [05:20<7:57:35,  1.16s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.9161601066589355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 240/25000 [05:22<8:04:16,  1.17s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.720252275466919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 241/25000 [05:23<7:57:30,  1.16s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6421923637390137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 242/25000 [05:24<7:52:43,  1.15s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6440112590789795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 243/25000 [05:25<8:11:48,  1.19s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.581847667694092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 244/25000 [05:26<7:40:09,  1.12s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.4561917781829834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 245/25000 [05:27<7:33:57,  1.10s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.8947956562042236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 246/25000 [05:28<7:26:12,  1.08s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.8134548664093018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 247/25000 [05:29<7:49:52,  1.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.4619171619415283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 248/25000 [05:31<7:49:26,  1.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.407609224319458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 249/25000 [05:31<7:23:45,  1.08s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.9134483337402344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WJYptS9vIeND",
        "colab": {}
      },
      "source": [
        "dev_inp_tensor = torch.tensor(inp_voc.to_matrix(dev_inp[::500])).to(torch.int64).to(device)\n",
        "for inp_line, trans_line in zip(dev_inp[::500], model.translate_lines(dev_inp_tensor)[0]):\n",
        "    print(inp_line)\n",
        "    print(trans_line)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}